{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeb8ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "milvus_client = MilvusClient(uri=\"http://localhost:19530\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "908be824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection_name=\"files\"\n",
    "# utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9cd3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'files' exists. Dropping it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 384\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"doc_name\", dtype=DataType.VARCHAR, max_length=200),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "]\n",
    "collection_name=\"files\"\n",
    "# Check if collection exists\n",
    "from pymilvus import utility\n",
    "if utility.has_collection(collection_name):\n",
    "    print(f\"Collection '{collection_name}' exists. Dropping it...\")\n",
    "    utility.drop_collection(collection_name)\n",
    "else:\n",
    "    print(f\"Collection '{collection_name}' does not exist.\")\n",
    "    \n",
    "schema = CollectionSchema(fields, description=\"Whole-PDF embeddings\")\n",
    "collection = Collection(collection_name, schema)\n",
    "index_params = {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"IP\", \"params\": {\"nlist\": 128}}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a6283c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All PDFs stored in Milvus!\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def pdf_to_text(path):\n",
    "    doc = fitz.open(path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "dataset_folder = \"/home/natcha/rag_document/dataset\"\n",
    "pdf_files = [f for f in os.listdir(dataset_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(dataset_folder, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        embedding = model.encode([page_text])[0].tolist()\n",
    "        doc_name = f\"{pdf_file}_page_{i}\"\n",
    "        data = [\n",
    "                [doc_name], \n",
    "                [embedding]\n",
    "            ]\n",
    "        collection.insert(data)\n",
    "\n",
    "collection.load()\n",
    "print(\"✅ All PDFs stored in Milvus!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eda9af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "no such file: '/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_11678/4268452502.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results_all\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m query_pdf_filepath = \u001b[33m\"/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m results_all = query_with_pdf(query_pdf_filepath, top_k=\u001b[32m5\u001b[39m)\n",
      "\u001b[32m/tmp/ipykernel_11678/4268452502.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(pdf_path, top_k)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m query_with_pdf(pdf_path, top_k=\u001b[32m5\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     doc = fitz.open(pdf_path)\n\u001b[32m      3\u001b[39m     results_all = []\n\u001b[32m      4\u001b[39m     similarity_scores = defaultdict(list)\n\u001b[32m      5\u001b[39m     top1_scores = []\n",
      "\u001b[32m~/anaconda3/envs/ragdoc/lib/python3.11/site-packages/pymupdf/__init__.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[39m\n\u001b[32m   3024\u001b[39m                     self.page_count2 = extra.page_count_pdf\n\u001b[32m   3025\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3026\u001b[39m                     self.page_count2 = extra.page_count_fz\n\u001b[32m   3027\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3028\u001b[39m             JM_mupdf_show_errors = JM_mupdf_show_errors_old\n",
      "\u001b[31mFileNotFoundError\u001b[39m: no such file: '/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf'"
     ]
    }
   ],
   "source": [
    "def query_with_pdf(pdf_path, top_k=5):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results_all = []\n",
    "    similarity_scores = defaultdict(list)   \n",
    "    top1_scores = []                        \n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        # Encode page text\n",
    "        query_vec = model.encode([page_text])[0].tolist()\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "        results = collection.search(\n",
    "            [query_vec],\n",
    "            \"embedding\",\n",
    "            param=search_params,\n",
    "            limit=top_k,\n",
    "            output_fields=[\"doc_name\"]\n",
    "        )\n",
    "        results_all.append((page_num, results))\n",
    "\n",
    "        \n",
    "        for hit in results[0]:\n",
    "            full_name = hit.entity.get(\"doc_name\")\n",
    "            pdf_base = full_name.split(\"_page_\")[0]\n",
    "            similarity_percentage = hit.score * 100\n",
    "            similarity_scores[pdf_base].append(similarity_percentage)\n",
    "\n",
    "\n",
    "    return results_all\n",
    "\n",
    "query_pdf_filepath = \"/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf\"\n",
    "results_all = query_with_pdf(query_pdf_filepath, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87aed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Similarity\n",
      "53.66%\n"
     ]
    }
   ],
   "source": [
    "first_similarities = []\n",
    "\n",
    "for page_num, hits in results_all:\n",
    "    if hits[0]:  \n",
    "        first_hit = hits[0][0]\n",
    "        similarity_percentage = first_hit.score * 100\n",
    "        first_similarities.append({\n",
    "            \"Query Page\": page_num,\n",
    "            \"Matched PDF\": first_hit.entity.get('doc_name'),\n",
    "            \"Similarity (%)\": f\"{similarity_percentage:.2f}\"\n",
    "        })\n",
    "overall_avg = sum([float(item[\"Similarity (%)\"]) for item in first_similarities]) / len(first_similarities) if first_similarities else 0\n",
    "print(f\"\\nOverall Average Similarity\\n{overall_avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7781f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Query Page 0 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 57.86%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 51.06%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 50.42%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 49.57%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 48.21%\n",
      "--- Query Page 1 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 53.91%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.27%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 49.08%\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_1 | Score: 48.92%\n",
      "Matched PDF: 1-s2.0-S2772485925000481-main.pdf_page_1 | Score: 47.65%\n",
      "--- Query Page 2 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 54.33%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.25%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.36%\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_15 | Score: 50.15%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 48.99%\n",
      "--- Query Page 3 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.68%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 53.53%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 53.21%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_7 | Score: 52.83%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_52 | Score: 52.83%\n",
      "--- Query Page 4 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 60.87%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 50.47%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.02%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 44.66%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 43.41%\n",
      "--- Query Page 5 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.49%\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_5 | Score: 45.82%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.22%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 45.18%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 43.75%\n",
      "--- Query Page 6 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 56.63%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.26%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 55.64%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 55.37%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 54.49%\n",
      "--- Query Page 7 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 53.27%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_62 | Score: 50.64%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 50.41%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 50.13%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 46.22%\n",
      "--- Query Page 8 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 43.99%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 40.78%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 40.72%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 40.10%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 39.82%\n",
      "--- Query Page 9 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 46.59%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 42.81%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 42.22%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 41.60%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 41.43%\n",
      "--- Query Page 10 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 48.73%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 41.98%\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_1 | Score: 41.04%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 41.04%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 40.20%\n",
      "--- Query Page 11 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 57.43%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 52.82%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 51.42%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 51.33%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 51.21%\n",
      "--- Query Page 12 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 56.74%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 50.87%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_19 | Score: 50.11%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 49.90%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 49.58%\n",
      "--- Query Page 13 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_4 | Score: 56.80%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 55.56%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 54.25%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.31%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 51.98%\n",
      "--- Query Page 14 ---\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 44.42%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_10 | Score: 43.63%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 43.29%\n",
      "Matched PDF: 1-s2.0-S1071581925001466-main.pdf_page_13 | Score: 42.74%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_3 | Score: 42.31%\n",
      "--- Query Page 15 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 56.80%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_1 | Score: 50.90%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 47.46%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.71%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 45.33%\n"
     ]
    }
   ],
   "source": [
    "# Print page-level matches\n",
    "for page_num, hits in results_all:\n",
    "    print(f\"--- Query Page {page_num} ---\")\n",
    "    for hit in hits[0]:\n",
    "        similarity_percentage = hit.score * 100\n",
    "        print(f\"Matched PDF: {hit.entity.get('doc_name')} | Score: {similarity_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe044fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this. The user wants me to highlight and explain similarities between the query and matched PDF texts. First, task 1 is to identify key sentences or paragraphs that have similar ideas. Then, show them from both texts and explain why they're similar.\n",
      "\n",
      "Starting with the query page. I need to look for the main ideas. The first paragraph talks about LLM-generated text issues like bias, information accuracy, and potential problems. The matched PDF has similar content about the same topics. So that's a good start.\n",
      "\n",
      "Next, the second paragraph in the query mentions paraphrasing attacks. The matched PDF also has similar content on paraphrasing attacks, which are vulnerabilities in current detectors. Then, the third paragraph in the query discusses detection methods like zero-shot and watermarking, which are similar to the matched PDF's approaches.\n",
      "\n",
      "Now, the matched PDF has specific details: for example, in the zero-shot detectors, they use RoBERTa and GROVER, which are similar to the query's mention of these models. The watermarking scheme with tokens in the 'green list' is also a key part of both texts.\n",
      "\n",
      "I need to make sure each highlighted part is clearly explained. For the query, the first paragraph's main idea is straightforward. The matched PDF's second paragraph is a direct repetition. Then, the third paragraph's main idea is consistent with the matched PDF's third paragraph. Also, the detection methods in the query's second paragraph and the matched PDF's third paragraph are similar.\n",
      "\n",
      "Wait, the user's first task is to highlight sentences or paragraphs. So I need to find the key points. Let me check again. The query's first paragraph has issues with LLMs. The matched PDF has the same. Then, the second paragraph on paraphrasing attacks. The query's third paragraph on detection methods. Then, the matched PDF's zero-shot and watermarking parts. Yeah, that's all. Now, explain why each part is similar. For example, the query's first paragraph is about the same problem as the matched PDF's, so they are similar. The second paragraph is about paraphrasing attacks which match the third paragraph in the matched PDF. The detection methods in the query's second and matched PDF's third paragraphs are similar.\n",
      "\n",
      "Make sure the explanations are clear and natural. Avoid technical jargon. Also, check that all highlighted parts are correctly identified and explained.\n",
      "</think>\n",
      "\n",
      "**1. Highlighted Sentences/Paragraphs:**  \n",
      "- **Query Page:**  \n",
      "  - \"LLM-generated text issues like bias, information accuracy, and potential problems with automatic text generation\" (first paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (second paragraph).  \n",
      "  - \"Detection methods like zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "- **Matched PDF:**  \n",
      "  - \"LLM-generated text issues such as bias and information accuracy\" (second paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (third paragraph).  \n",
      "  - \"Detection methods including zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "**2. Explanation:**  \n",
      "- The query’s first paragraph highlights the same core problems as the matched PDF’s second paragraph, focusing on biases, accuracy, and detection vulnerabilities.  \n",
      "- The matched PDF’s second paragraph directly repeats the issue with paraphrasing attacks, which aligns with the query’s third paragraph on detection vulnerabilities.  \n",
      "- The third paragraph of the query and the third paragraph of the matched PDF both emphasize detection methods (zero-shot and watermarking), making these parts similar in content and structure.  \n",
      "\n",
      "These sections share a logical flow, with the query building on similar themes to the matched PDF, reinforcing consistency in information.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_page_text(pdf_path, page_number):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    if page_number < len(doc):\n",
    "        text = doc[page_number].get_text(\"text\")\n",
    "    else:\n",
    "        text = \"\"\n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "\n",
    "query_pdf = extract_page_text(\"/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf\", 1)      # page 1\n",
    "matched_pdf = extract_page_text(\"/home/natcha/rag_document/dataset/1-s2.0-S2949719125000275-main.pdf\", 3)\n",
    "similarity_percentage = 53.91\n",
    "\n",
    "# Run a prompt on qwen3:0.6b-q4_K_M\n",
    "response = ollama.generate(\n",
    "    model=\"qwen3:0.6b-q4_K_M\",\n",
    "    prompt=f\"\"\"\n",
    "You are analyzing two pieces of text from different PDF pages.\n",
    "Compare the following two PDF page texts and justify why their similarity score is {similarity_percentage}%.  \n",
    "\n",
    "Here is the query page text:\n",
    "---\n",
    "{query_pdf}\n",
    "---\n",
    "\n",
    "Here is the matched database page text:\n",
    "---\n",
    "{matched_pdf}\n",
    "---\n",
    "\n",
    "Tasks:\n",
    "1. Highlight sentences or paragraphs from the query page that have similar information or main idea.  \n",
    "2. Show the corresponding sentences or paragraphs from the matched PDF.  \n",
    "3. Explain briefly why these parts are considered similar in clear, natural language. \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(response[\"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text:\n",
      "\n",
      "**1. Highlighted Sentences/Paragraphs:**  \n",
      "- **Query Page:**  \n",
      "  - \"LLM-generated text issues like bias, information accuracy, and potential problems with automatic text generation\" (first paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (second paragraph).  \n",
      "  - \"Detection methods like zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "- **Matched PDF:**  \n",
      "  - \"LLM-generated text issues such as bias and information accuracy\" (second paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (third paragraph).  \n",
      "  - \"Detection methods including zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "**2. Explanation:**  \n",
      "- The query’s first paragraph highlights the same core problems as the matched PDF’s second paragraph, focusing on biases, accuracy, and detection vulnerabilities.  \n",
      "- The matched PDF’s second paragraph directly repeats the issue with paraphrasing attacks, which aligns with the query’s third paragraph on detection vulnerabilities.  \n",
      "- The third paragraph of the query and the third paragraph of the matched PDF both emphasize detection methods (zero-shot and watermarking), making these parts similar in content and structure.  \n",
      "\n",
      "These sections share a logical flow, with the query building on similar themes to the matched PDF, reinforcing consistency in information.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Get the actual text from the response object\n",
    "response_text = response[\"response\"]  # or response.response if it's an attribute\n",
    "\n",
    "# Use regex to capture everything after </think>\n",
    "match = re.search(r\"</think>\\s*(.*)\", response_text, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    extracted_text = match.group(1).strip()\n",
    "else:\n",
    "    extracted_text = \"\"\n",
    "\n",
    "print(\"Extracted text:\\n\")\n",
    "print(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
