{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb8ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natcha/anaconda3/envs/ragdoc/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908be824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection_name=\"files\"\n",
    "# utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9cd3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'files' exists. Dropping it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 384\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"doc_name\", dtype=DataType.VARCHAR, max_length=200),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),\n",
    "]\n",
    "collection_name=\"files\"\n",
    "# Check if collection exists\n",
    "if utility.has_collection(collection_name):\n",
    "    print(f\"Collection '{collection_name}' exists. Dropping it...\")\n",
    "    utility.drop_collection(collection_name)\n",
    "else:\n",
    "    print(f\"Collection '{collection_name}' does not exist.\")\n",
    "    \n",
    "schema = CollectionSchema(fields, description=\"Whole-PDF embeddings\")\n",
    "collection = Collection(collection_name, schema)\n",
    "index_params = {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"IP\", \"params\": {\"nlist\": 128}}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6283c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All PDFs stored in Milvus!\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def pdf_to_text(path):\n",
    "    doc = fitz.open(path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "dataset_folder = \"/home/natcha/rag_document/dataset\"\n",
    "pdf_files = [f for f in os.listdir(dataset_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(dataset_folder, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        embedding = model.encode([page_text])[0].tolist()\n",
    "        doc_name = f\"{pdf_file}_page_{i}\"\n",
    "        data = [\n",
    "                [doc_name], \n",
    "                [embedding]\n",
    "            ]\n",
    "        collection.insert(data)\n",
    "\n",
    "collection.load()\n",
    "print(\"✅ All PDFs stored in Milvus!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eda9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_pdf(pdf_path, top_k=5):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results_all = []\n",
    "    similarity_scores = defaultdict(list)   # per-PDF averages\n",
    "    top1_scores = []                        # only first/top match per page\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        # Encode page text\n",
    "        query_vec = model.encode([page_text])[0].tolist()\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "        results = collection.search(\n",
    "            [query_vec],\n",
    "            \"embedding\",\n",
    "            param=search_params,\n",
    "            limit=top_k,\n",
    "            output_fields=[\"doc_name\"]\n",
    "        )\n",
    "        results_all.append((page_num, results))\n",
    "\n",
    "        # Collect similarity scores for per-PDF averages (all top-k)\n",
    "        for hit in results[0]:\n",
    "            full_name = hit.entity.get(\"doc_name\")\n",
    "            pdf_base = full_name.split(\"_page_\")[0]\n",
    "            similarity_percentage = hit.score * 100\n",
    "            similarity_scores[pdf_base].append(similarity_percentage)\n",
    "\n",
    "\n",
    "    return results_all\n",
    "\n",
    "query_pdf_filepath = \"/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf\"\n",
    "results_all = query_with_pdf(query_pdf_filepath, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87aed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Similarity\n",
      "53.66%\n"
     ]
    }
   ],
   "source": [
    "first_similarities = []\n",
    "\n",
    "for page_num, hits in results_all:\n",
    "    if hits[0]:  # Check if there is at least one result\n",
    "        first_hit = hits[0][0]\n",
    "        similarity_percentage = first_hit.score * 100\n",
    "        first_similarities.append({\n",
    "            \"Query Page\": page_num,\n",
    "            \"Matched PDF\": first_hit.entity.get('doc_name'),\n",
    "            \"Similarity (%)\": f\"{similarity_percentage:.2f}\"\n",
    "        })\n",
    "overall_avg = sum([float(item[\"Similarity (%)\"]) for item in first_similarities]) / len(first_similarities) if first_similarities else 0\n",
    "print(f\"\\nOverall Average Similarity\\n{overall_avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7781f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Query Page 0 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 57.86%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 51.06%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 50.42%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 49.57%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 48.21%\n",
      "--- Query Page 1 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 53.91%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.27%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 49.08%\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_1 | Score: 48.92%\n",
      "Matched PDF: 1-s2.0-S2772485925000481-main.pdf_page_1 | Score: 47.65%\n",
      "--- Query Page 2 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 54.33%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.25%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.36%\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_15 | Score: 50.15%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 48.99%\n",
      "--- Query Page 3 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.68%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 53.53%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 53.21%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_7 | Score: 52.83%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_52 | Score: 52.83%\n",
      "--- Query Page 4 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 60.87%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 50.47%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.02%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 44.66%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 43.41%\n",
      "--- Query Page 5 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.49%\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_5 | Score: 45.82%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.22%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 45.18%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 43.75%\n",
      "--- Query Page 6 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 56.63%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.26%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 55.64%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 55.37%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 54.49%\n",
      "--- Query Page 7 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 53.27%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_62 | Score: 50.64%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 50.41%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 50.13%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 46.22%\n",
      "--- Query Page 8 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 43.99%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 40.78%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 40.72%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 40.10%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 39.82%\n",
      "--- Query Page 9 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 46.59%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 42.81%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 42.22%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 41.60%\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 41.43%\n",
      "--- Query Page 10 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 48.73%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 41.98%\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_1 | Score: 41.04%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 41.04%\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 40.20%\n",
      "--- Query Page 11 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 57.43%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 52.82%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 51.42%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 51.33%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 51.21%\n",
      "--- Query Page 12 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 56.74%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 50.87%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_19 | Score: 50.11%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 49.90%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 49.58%\n",
      "--- Query Page 13 ---\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_4 | Score: 56.80%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 55.56%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 54.25%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.31%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 51.98%\n",
      "--- Query Page 14 ---\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 44.42%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_10 | Score: 43.63%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 43.29%\n",
      "Matched PDF: 1-s2.0-S1071581925001466-main.pdf_page_13 | Score: 42.74%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_3 | Score: 42.31%\n",
      "--- Query Page 15 ---\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 56.80%\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_1 | Score: 50.90%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 47.46%\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.71%\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 45.33%\n"
     ]
    }
   ],
   "source": [
    "# Print page-level matches\n",
    "for page_num, hits in results_all:\n",
    "    print(f\"--- Query Page {page_num} ---\")\n",
    "    for hit in hits[0]:\n",
    "        similarity_percentage = hit.score * 100\n",
    "        print(f\"Matched PDF: {hit.entity.get('doc_name')} | Score: {similarity_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe044fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query Page 0 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 57.86%\n",
      "The similarity score of 57.86% between the query and matched pages is due to their shared focus on methodologies for distinguishing between LLM-generated and human-written texts. Here's the breakdown:\n",
      "\n",
      "**Similarity Highlights:**\n",
      "1. **Dataset Focus:**  \n",
      "   Both texts discuss the same dataset: human-written term summaries, LLM-generated texts, and paraphrased content. The query emphasizes the use of this dataset for stylometry-based detection, while the matched text highlights its role in LLM-generated text detection.\n",
      "\n",
      "2. **Methodology and Techniques:**  \n",
      "   The query integrates machine learning features (e.g., StyloMetrix and n-gram-based features) to classify text types, mirroring the matched text's approach to identify stylistic patterns. Both papers address how LLMs distinguish between models, emphasizing the role of model attribution and ethical AI use.\n",
      "\n",
      "**Justification:**  \n",
      "The similarity stems from the alignment in research objectives (methodology for detection and attribution) and the shared focus on improving text distinction. The high score reflects the clear overlap in key themes and the structural similarity in both texts.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 51.06%\n",
      "1. **Similarity Highlight:**  \n",
      "   The query page discusses stylometry as a method to distinguish between human and LLM-generated texts, while the matched file explores how human-written paraphrases (H-PP) improve detection accuracy. Both texts emphasize the use of classification techniques (tree-based models, n-gram-based features) and the effectiveness of including H-PP in training datasets.\n",
      "\n",
      "2. **Matched Page Text:**  \n",
      "   - **Query Page Text:** Highlights the methodology of stylometry, the dataset (Wikipedia), and the classification pipeline.  \n",
      "   - **Matched Page Text:** Discusses the role of human paraphrases in training detectors, the impact of different paraphrasing methods, and how including H-PP improves performance.  \n",
      "\n",
      "3. **Similarity Explanation:**  \n",
      "   Both texts address the same core concepts: the application of stylometry in detecting LLM-generated text, the use of human paraphrases, and the importance of including them in training datasets. The similarity lies in the shared focus on detection accuracy and the integration of human-generated data, which contribute to a 51.06% similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 50.42%\n",
      "**Similarity Explanation:**  \n",
      "The query and matched PDF pages both focus on the application of LLMs (Large Language Models) in text analysis, particularly in stylometry and paraphrase generation. The query text describes the creation of a benchmark dataset for distinguishing between human and LLM-generated texts, including features like lexical, grammatical, and syntactic patterns. The matched file also discusses similar research on model detection, emphasizing the use of various text summarization methods and classification techniques. This overlap in topics, methodologies, and outcomes (e.g., performance metrics, dataset types) justifies the similarity score of 50.42%.  \n",
      "\n",
      "**Similar Sentences or Paragraphs:**  \n",
      "1. **Query Page:**  \n",
      "   - \"Stylometry recognizes human and LLM-generated texts in short samples\" (highlighting LLMs detecting human text).  \n",
      "   - \"By applying it to LLM-generated texts, we identify their emergent writing patterns.\" (methodology and results).  \n",
      "   - \"The 10-sentence long texts were classiﬁed by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features.\" (methodology and classification).  \n",
      "\n",
      "2. **Matched Page:**  \n",
      "   - \"Models’ learning of language representations, including syntactic, contextual and semantic information (Goyal et al., 2023).\" (methodology and data sources).  \n",
      "   - \"Text data from large corpora are used to train LLMs, such as CommonCrawl, Web-Text2, BookCorpus, etc.\" (data sources and model training).  \n",
      "   - \"The use of LLMs along with a simple chat interface has attracted massive usage and attention from the general public.\" (application and public impact).  \n",
      "\n",
      "**Justification:**  \n",
      "Both texts discuss LLMs in the context of text analysis, their application, and the development of tools for distinguishing between human and machine-generated texts. The overlap in focus and methodology justifies the high similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 49.57%\n",
      "1. **Highlighted sentences**:  \n",
      "   - \"Language models are trained to follow instructions, requiring careful attention to their structure and behavior.\"  \n",
      "   - \"Pretraining involves training models on large corpora to enhance their performance, ensuring they generalize across different tasks.\"  \n",
      "   - \"Emergent analogical reasoning arises from the model's ability to draw connections between related concepts, improving its understanding of complex relationships.\"  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   These sentences highlight key aspects of language model training, such as \"instructions for follow-up\" and \"pretraining on large corpora.\" They emphasize the role of pretraining in shaping model performance and the emergence of analogical reasoning, which aligns with the query's focus on model behavior and reasoning.  \n",
      "\n",
      "3. **Why these parts are similar**:  \n",
      "   The query discusses training processes and model performance, while the PDF emphasizes pretraining, generalization, and reasoning mechanisms. The highlighted sentences reflect these core concepts, making them directly relevant to the query's main ideas.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 48.21%\n",
      "The similarity score of 48.21% between the query and matched PDF pages is justified by the shared focus on **stylometry and LLM-generated text detection**. Both texts discuss:\n",
      "\n",
      "1. **Stylometry and authorship attribution**: The query text highlights the use of stylometry to distinguish between LLM-generated and human texts, while the matched text references similar techniques in LLM detection.  \n",
      "2. **Classification methods**: The query text describes tools like n-gram pipelines and StyloMetrix for distinguishing models, while the matched text introduces datasets and classification experiments using SOTA paraphrasing models.  \n",
      "3. **Paraphrasing and accuracy**: Both texts address the role of human paraphrasing in improving detection accuracy, with the query text emphasizing performance metrics and the matched text detailing experiments on this.  \n",
      "\n",
      "The overlap in focus on LLM-generated text detection, paraphrasing, and classification accuracy ensures the similarity score reflects a clear thematic alignment.\n",
      "\n",
      "=== Query Page 1 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 53.91%\n",
      "1. **Highlight sentences or paragraphs**:  \n",
      "   - **Query Page**:  \n",
      "     - *You are to highlight sentences or paragraphs from the query page that have similar information or main idea.*  \n",
      "     - *The matched PDF has similar content as the query.*  \n",
      "\n",
      "   - **Matched PDF**:  \n",
      "     - *Similar to the query, both focus on identifying content based on similarity.*  \n",
      "\n",
      "2. **Explain similarity**:  \n",
      "   Both sections emphasize the importance of identifying content based on similarity, aligning the query and matched PDF in content and structure. The query’s focus on highlighting similar information mirrors the matched PDF’s purpose.  \n",
      "\n",
      "**Why they are similar**:  \n",
      "- Both sections aim to highlight content that aligns with the query’s main idea, reinforcing the importance of similarity-based detection.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.27%\n",
      "1. **Highlighted Sentences:**  \n",
      "   - **Query:** \"K. Przystalski et al. et al. ensuring that language models are used ethically should account for such issues as bias, misinformation, and the potential for generating harmful content.\"  \n",
      "   - **Matched:** \"D.T. Pele et al. suggest that general-purpose LLMs, particularly GPT-3.5, offer viable tools for estimating VaR and ES in contexts where agility and numerical precision are critical.\"  \n",
      "   - **Explanation:** Both documents discuss LLMs' ethical use and practical applications. The query emphasizes ethical concerns in language models, while the matched text highlights their utility in financial risk analysis.  \n",
      "\n",
      "2. **Matched Paragraphs:**  \n",
      "   - **Query:** \"The research presented in this paper provides an innovative approach to distinguish between models.\"  \n",
      "   - **Matched:** \"This manuscript is structured into six sections including Sections 1–6.\"  \n",
      "   - **Explanation:** Both documents discuss the structure and purpose of the paper. The query emphasizes innovation in research, while the matched text mentions the organization of the paper.  \n",
      "\n",
      "3. **Similarity Explanation:**  \n",
      "   - The query and matched text both focus on the role of LLMs in AI research and their practical applications (ethical use, classification, financial risk analytics). The matched document's structure and purpose align with the query's emphasis on the organization and purpose of the paper.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 49.08%\n",
      "1. **Highlighting Similarity**:  \n",
      "   - **Query Page**: The text emphasizes the use of stylometry for authorship attribution and its effectiveness in distinguishing LLM-generated vs. human texts. It also highlights the contributions and performance metrics (e.g., AUC scores, classification accuracy) of the study.  \n",
      "   - **Matched Page**: The matched text discusses the structure of the study, its relevance to stylometry, and the role of LLMs in NLG. It also mentions the data collection strategy, performance metrics, and the ethical implications of AI use.  \n",
      "\n",
      "2. **Corresponding Sentences/Paragraphs**:  \n",
      "   - **Query Page**: Sections 1–6 address the research’s rationale, background, experimental design, classification methods, ethical implications, and future directions.  \n",
      "   - **Matched Page**: The text outlines the study’s structure, its focus on stylometry and authorship attribution, and the challenges in detecting LLM-generated texts.  \n",
      "\n",
      "3. **Similarity Justification**:  \n",
      "   - Both documents discuss the application of stylometry, the effectiveness of methods (e.g., AUC scores), and the ethical concerns surrounding AI-generated texts. The overlap in structure and content (e.g., experimental design, performance metrics, and methodology) explains the high similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_1 | Score: 48.92%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: Sections about applying stylometric techniques to distinguish between LLM outputs and human data, along with examples of LLMs' performance in tasks like language generation.  \n",
      "   - **Matched PDF**: Sections discussing similar contributions, such as LLMs' ability to generate complex data (e.g., networks) and their internal dynamics (e.g., biases in response patterns).  \n",
      "\n",
      "2. **Corresponding Sentences**:  \n",
      "   - **Query**: A paragraph on stylometric applications and LLMs' role in educational surveys.  \n",
      "   - **Matched**: A section on LLMs' internal structure and their biases in survey responses.  \n",
      "\n",
      "3. **Explanation**:  \n",
      "   Both texts focus on the **capabilities and limitations of LLMs**, with the query emphasizing their role in tasks like language generation and stylometric analysis, while the matched PDF highlights their internal processing and response biases. This shared theme directly explains the similarity score of 48.92%.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2772485925000481-main.pdf_page_1 | Score: 47.65%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: \"K. Przystalski et al.\"  \n",
      "     - **Matched File**: \"M.-K. Mak and T. Luo.\"  \n",
      "   - **Similarity**: Both authors identify the focus on bias in AI systems, with the query highlighting the paper’s contributions and relevance to AI research, while the matched file emphasizes bias in LLMs.  \n",
      "\n",
      "2. **Corresponding Sentences**:  \n",
      "   - **Query Page**: \"This paper presents a structured approach to bias in AI systems, with contributions to the field.\"  \n",
      "     - **Matched File**: \"This review explores bias in AI systems, with a focus on LLMs and their limitations.\"  \n",
      "\n",
      "3. **Explanation**:  \n",
      "   Both papers discuss similar themes of bias in AI systems, with the query emphasizing the paper’s structure and contributions, while the matched file focuses on bias in LLMs and AI’s limitations. The similarity lies in their alignment with the core ideas of the topic, such as the role of bias in AI models and their implications for accuracy and fairness.\n",
      "\n",
      "=== Query Page 2 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 54.33%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - Query: \"Zero-shot and watermark detectors are effective in detecting LLM-generated text.\"  \n",
      "   - Matched PDF: \"Zero-shot and watermark detectors are effective in detecting LLM-generated text.\"  \n",
      "   - **Explanation**: Both sentences highlight the comparison between zero-shot and watermark-based detection methods, emphasizing their effectiveness in identifying LLM-generated content.  \n",
      "\n",
      "2. **Matched PDF Sentences**:  \n",
      "   - PDF: \"Zero-shot classifiers aim to identify patterns and statistical characteristics of input text, comparing them to those of LLM-generated text.\"  \n",
      "   - PDF: \"Watermark detectors rely on the addition of a watermark, which is not visible to humans, on LLM-generated text.\"  \n",
      "\n",
      "3. **Reasoning**:  \n",
      "   These parts are similar because both the query and the PDF discuss detection methods, with the query emphasizing the effectiveness of these techniques in identifying LLM-generated text. The matched sentences directly address the comparison between these detection approaches.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 53.25%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: \"PaLM, discussing their design, strengths, and limitations. The paper explores various methods used for constructing and enhancing LLMs, examines key datasets utilized for training and evaluation, and assesses these models’ performance across standard benchmarks.\"  \n",
      "   - **Matched File**: \"Argamon (2018) contributes with Computational forensic authorship analysis: Promises and pitfalls – a comprehensive examination of the techniques involved in computational authorship analysis, focusing on their application within legal and forensic contexts.\"  \n",
      "\n",
      "   **Similarity**: Both sections discuss authorship methods (e.g., computational tools, forensic applications) and their role in legal contexts, highlighting their focus on methodologies and practical applications.\n",
      "\n",
      "2. **Matched Paragraphs**:  \n",
      "   - **Query Page**: \"LLMs’ advancements in natural language tasks.\"  \n",
      "   - **Matched File**: \"Neural networks learning stylometric features.\"  \n",
      "\n",
      "   **Similarity**: Both focus on the role of neural networks in authorship analysis, emphasizing their effectiveness in capturing natural language patterns and their application in the field.  \n",
      "\n",
      "3. **Explanations**:  \n",
      "   - Both sections center on authorship methods, methodologies, and practical applications (e.g., legal or forensic contexts). The key similarity lies in their emphasis on the effectiveness of neural networks in analyzing and enhancing LLMs, which are central to the field. This overlaps in content and purpose, making the paragraphs highly similar.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.36%\n",
      "The similarity score of 50.36% between the query page and the matched file is due to overlapping content in key areas related to LLMs and authorship analysis. Here's the breakdown:\n",
      "\n",
      "1. **Common Themes**:  \n",
      "   - Both texts discuss **LLM advancements in natural language tasks** (query) and **computational authorship techniques** (matched).  \n",
      "   - They emphasize **data scale** and **datasets** in improving model performance, as seen in the query's section on training.  \n",
      "\n",
      "2. **Specific Repeated Topics**:  \n",
      "   - The query mentions **authorship attribution** and **stylometric methods** (Ding et al., 2017) in the context of authorship analysis.  \n",
      "   - The matched file highlights **computational forensic authorship analysis** and **interpretable style embeddings** (Patel et al., 2023).  \n",
      "\n",
      "3. **Paraphrasing and Detection Models**:  \n",
      "   - The query discusses **paraphrasing** and its impact on LLM-generated text detection (as part of the study).  \n",
      "   - The matched file also references **Human & LLM Paraphrase Collection (HLPC)** and **paraphrase experiments** with both LLMs and human-generated texts.  \n",
      "\n",
      "These overlapping areas, along with shared focus on **data-driven model performance** and **authorship techniques**, justify the similarity score of 50.36%.\n",
      "\n",
      "Matched PDF: 1-s2.0-S074756322500216X-main.pdf_page_15 | Score: 50.15%\n",
      "The similarity score of 50.15% between the two PDF pages is due to their **overlapping content** in the main topic of **authorship in LLM-based systems**. Here's the breakdown:\n",
      "\n",
      "1. **Shared Content**:  \n",
      "   Both pages discuss **authorship and LLMs**, which are central to the query paper (K. Przystalski et al.) and the matched paper (Argamon et al.). The content overlaps in methods, datasets, and applications (e.g., computational forensic authorship), highlighting a **common theme**.\n",
      "\n",
      "2. **Similarity Reasoning**:  \n",
      "   The pages share similar ideas about:  \n",
      "   - **LLM design and performance** (from K. Przystalski and Argamon).  \n",
      "   - **Computational authorship techniques** and their implementation (from both papers).  \n",
      "\n",
      "3. **Conclusion**:  \n",
      "   The high similarity is driven by the **overlap in core research areas**, making the content highly relevant and structurally similar.  \n",
      "\n",
      "**Reason**: The two pages collectively focus on the same topic, leading to a high overlap in content and reasoning.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 48.99%\n",
      "**1. Highlight sentences or paragraphs from the query page that have similar information or main idea:**  \n",
      "- **Query Page:**  \n",
      "  \"PaLM, discussing their design, strengths, and limitations. The paper explores various methods used for constructing and enhancing LLMs, examines key datasets utilized for training and evaluation, and assesses these models’ performance across standard benchmarks.\"  \n",
      "  **Matched Page:**  \n",
      "  \"Learning stylometric representations for authorship analysis (Ding et al., 2017) explores a neural network approach to learn stylometric representations that capture various linguistic features such as topical, lexical, syntactical, and character-level characteristics.\"  \n",
      "\n",
      "**Explanation:** Both pages discuss the role of neural networks in authorship analysis, focusing on linguistic features and model capabilities.  \n",
      "\n",
      "**2. Show the corresponding sentences or paragraphs from the matched PDF:**  \n",
      "- **Query Page:**  \n",
      "  \"Argamon (2018) contributes with Computational forensic authorship analysis: Promises and pitfalls – a comprehensive examination of the techniques involved in computational authorship analysis, focusing on their application within legal and forensic contexts.\"  \n",
      "  **Matched Page:**  \n",
      "  \"Learning interpretable style embeddings via prompting LLMs (Patel et al., 2023) presents an innovative approach for deriving interpretable style embeddings, called LISA embeddings, from LLMs using prompting techniques.\"  \n",
      "\n",
      "**Explanation:** Both pages discuss the development of interpretable style embeddings, highlighting the use of LLMs and prompting techniques.  \n",
      "\n",
      "**3. Explain why these parts are considered similar in clear, natural language:**  \n",
      "- The query and matched pages share a common focus on neural network methods for authorship analysis and style embedding, as well as LLM capabilities. Both emphasize linguistic features and model performance, aligning their content and structure.\n",
      "\n",
      "=== Query Page 3 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.68%\n",
      "1. **Query Page:**  \n",
      "   The query highlights sentences about H-PP (human paraphrases) in the context of LLM-generated text detection and classification effectiveness. For example:  \n",
      "   - *\"the significant improvement in TPR@1%FPR and the importance...\"* (from the query).  \n",
      "\n",
      "2. **Matched PDF:**  \n",
      "   The matched PDF also discusses similar ideas, such as:  \n",
      "   - *\"the importance of ensuring minimal misclassification...\"* (from the matched text).  \n",
      "\n",
      "3. **Explanation:**  \n",
      "   Both texts focus on the effectiveness of H-PP in classification, emphasizing its role in improving detection metrics like TPR@1%FPR. The query and matched text share a clear focus on the impact of H-PP on classification outcomes, making these parts directly related.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 53.53%\n",
      "Comparing the query and matched PDF pages, the similarity score of 53.53% can be justified by the following key points:  \n",
      "\n",
      "**1. Similarity in Detection Methodologies**:  \n",
      "- **Query Page**: Describes zero-shot classifiers and watermark detectors, both of which identify LLM-generated texts based on patterns or presence of watermarks.  \n",
      "- **Matched Page**: Discusses the performance of detectors (zero-shot and watermark) and their effectiveness in distinguishing human and LLM-generated texts.  \n",
      "\n",
      "**2. Impact of Human-Paraphrased Texts**:  \n",
      "- **Query Page**: Highlights how human-written paraphrases affect detection performance, promoting TPR@1%FPR with trade-offs.  \n",
      "- **Matched Page**: Shows that paraphrased texts similarly influence detector performance, with similar metrics.  \n",
      "\n",
      "**3. Role of Watermarking**:  \n",
      "- **Query Page**: Emphasizes watermarking as a key factor in LLM-generated text detection, linking it to the inclusion of human paraphrases.  \n",
      "- **Matched Page**: Discusses the effectiveness of watermarking by LLM-generated texts, aligning with the query's focus on performance metrics.  \n",
      "\n",
      "**4. Main Ideas**:  \n",
      "- Both texts focus on the detection of LLM-generated vs. human-written texts, methodology, and the impact of paraphrasing. The structure and content mirror each other, confirming the similarity.  \n",
      "\n",
      "These elements collectively explain the 53.53% similarity, highlighting overlapping themes in detection techniques, performance metrics, and the role of human and LLM-generated texts.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 53.21%\n",
      "**1. Highlighted Sentences/Paragraphs from the Query Page with Similar Information/Main Idea:**  \n",
      "- **Query Page:**  \n",
      "  - \"When evaluating MGT detectors, caution is required with regard to training on data external to these benchmarks, as some of the data were collected from other primary sources.\"  \n",
      "  - \"We refer to the Overview of the 'Voight-Kampff' Generative AI Author-ship Verification Task at PAN and ELOQUENT 2024 by Bevendorff et al. (2024) as a recent benchmark of available methods.\"  \n",
      "- **Matched File:**  \n",
      "  - \"We do not cover the issue of mixed texts (human-edited MGT or LLM-edited human-written texts or texts whose separate parts come from either human or machine).\"  \n",
      "\n",
      "**2. Corresponding Sentences/Paragraphs from the Matched File:**  \n",
      "- **Query Page:**  \n",
      "  - \"A number of issues can degrade the performance of MGT detection. Wu et al. (2025) divided them into out-of-distribution challenges and attacks.\"  \n",
      "  - \"The potential attacks include: paraphrase (where LLM output is subsequently paraphrased by another model in order to change the textual feature distribution of the original MGT; Sadasivan et al., 2025, see, e.g.,), adversarial (involving textual perturbations on the level of characters like various misspelling strategies, Stiff & Johansson, 2022, see , syntax, Bhat & Parthasarathy, 2020, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or lexis, Crothers et al., 2022, see , or\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_7 | Score: 52.83%\n",
      "**Highlighting Similarity:**  \n",
      "1. **Query Page Text:**  \n",
      "   - \"When evaluating MGT detectors, caution is required with regard to training on data external to these benchmarks, as some of the data were collected from other primary sources.\"  \n",
      "   - \"We refer to the Overview of the “Voight-Kampﬀ” Generative AI Author-ship Verification Task at PAN and ELOQUENT 2024 by Bevendorﬀ et al. (2024) as a recent benchmark of available methods.\"  \n",
      "\n",
      "2. **Matched Page Text:**  \n",
      "   - \"provides a scientific basis and reference significance for subsequent research and industrial practice.\"  \n",
      "   - \"The development of LLMs can be roughly divided into four stages: the NLP phase, the basic model phase, the capability exploration stage, and the breakthrough development stage [18,19].\"  \n",
      "\n",
      "**Explanation of Similarity:**  \n",
      "- Both texts discuss the evolution of large language models (LLMs), with the query focusing on MGT detectors (a method for LLM validation) and the matched text highlighting the progression of LLMs. While the topics are distinct, the focus on development and the underlying principles of model advancement (e.g., language modeling, computational efficiency) are shared. This similarity lies in their thematic overlap, even though the contexts are different.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_52 | Score: 52.83%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   - **Query Page**:  \n",
      "     \"When evaluating MGT detectors, caution is required with regard to training on data external to these benchmarks, as some of the data were collected from other primary sources.\"  \n",
      "     *(This sentence highlights the importance of external data in training MGT detectors.)*  \n",
      "   - **Matched File**:  \n",
      "     \"Improved Content Understanding With Effective Use of Multi-task Contrastive Learning.\"  \n",
      "     *(This sentence discusses the application of multi-task learning in content understanding.)*  \n",
      "\n",
      "   **Explanation**: Both documents discuss the role of external data in MGT detection, with the query emphasizing external data sources and the matched file focusing on multi-task learning techniques.  \n",
      "\n",
      "2. **Matching Paragraphs**:  \n",
      "   - **Query Page**:  \n",
      "     \"We refer to the Overview of the “Voight-Kampﬀ” Generative AI Author-ship Veriﬁcation Task at PAN and ELOQUENT 2024 by Bevendorﬀ et al. (2024) as a recent benchmark of available methods.\"  \n",
      "     *(This sentence outlines a benchmark for LLM detection methods.)*  \n",
      "   - **Matched File**:  \n",
      "     \"A. Bindal, S. Ramanujam, D. Golland, et al., Improved Content Understanding With...\"  \n",
      "     *(This sentence discusses an improved approach for content understanding via multi-task learning.)*  \n",
      "\n",
      "   **Explanation**: Both documents reference benchmarks and methods related to LLM detection, aligning their focus on methodology and application.  \n",
      "\n",
      "3. **Similarity Justification**:  \n",
      "   The query and matched file share emphasis on MGT detection methods, external data training, and multi-task learning applications, which directly tie into the high similarity score. The key similarity lies in their focus on LLM detection techniques and their relevance to MGT watermarking and robustness challenges.\n",
      "\n",
      "=== Query Page 4 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_3 | Score: 60.87%\n",
      "1. **Similarity Highlighted**:  \n",
      "   - **Query**: The text discusses **zero-shot classifiers** and **watermark detectors** for LLM-generated text detection.  \n",
      "   - **Matched PDF**: Both sections mention similar detection methods (e.g., zero-shot classifiers and watermarking schemes).  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   The query emphasizes **approaches to LLM-generated text detection**, with zero-shot and watermark detectors as central methods. The matched PDF contains similar content, confirming the similarity in both structure and focus.  \n",
      "\n",
      "3. **Why These Parts Are Similar**:  \n",
      "   These sections highlight the **main idea of detecting text generated by LLMs**, using zero-shot classifiers and watermarking to identify patterns. The matched PDF aligns with this focus, showing that the query's key points are well-represented in the matched document.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 50.47%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   - **Query Page**:  \n",
      "     *First paragraph*: \"K. Przystalski et al. [...] introduces the field of adversarial stylometry. [...] This research area focuses on strategies like obfuscation and imitation to effectively counter authorship recognition methods.\"  \n",
      "     *Matched Page*:  \n",
      "     *First paragraph*: \"In conclusion, our findings suggest that general-purpose LLMs [...] offer viable tools for estimating VaR and ES in contexts where agility and numerical precision are critical.\"  \n",
      "   - **Explanation**: Both texts discuss the field of adversarial stylometry, its methods (obfuscation/imitation), and the effectiveness of those techniques. The matched text also aligns with the query's focus on LLMs and their applications in financial risk analytics.\n",
      "\n",
      "2. **Matched Page Text**:  \n",
      "   - **Query Page**:  \n",
      "     *Second paragraph*: \"The study demonstrates that manual techniques [...] are particularly effective at evading detection, often reducing the accuracy [...] to the level of random guesses.\"  \n",
      "     *Matched Page*:  \n",
      "     *Second paragraph*: \"The paper highlights several key concerns [...] including the potential for inherent biases [...] and the proper use of third-party content.\"  \n",
      "   - **Explanation**: Both texts focus on the effectiveness of manual techniques and the challenges they face, mirroring the query's emphasis on obfuscation and imitation as key methods.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 50.02%\n",
      "The similarity score of 50.02% between the query and matched PDF pages can be explained by the following key similarities:  \n",
      "\n",
      "1. **Effectiveness of Methods**: Both texts focus on the effectiveness of techniques (e.g., obfuscation, imitation) in counteracting authorship detection. The query text discusses manual techniques reducing stylometric accuracy, while the matched file also emphasizes obfuscation techniques.  \n",
      "\n",
      "2. **Role of Human-Paraphrased Texts**: Both documents highlight the use of human-generated texts and their paraphrasing in classification and detection. The query text mentions paraphrasing to evade detection, and the matched file similarly discusses the impact of paraphrased texts on model performance.  \n",
      "\n",
      "3. **Contextual Analysis**: Both texts explore the interplay between human-generated content and AI-generated outputs, such as in adversarial stylometry and AI-driven infodemics. The similarity lies in their shared focus on balancing human and AI-generated elements.  \n",
      "\n",
      "These points explain the high similarity score, highlighting overlapping themes in both texts.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 44.66%\n",
      "The similarity score of 44.66% between the query and matched PDF pages is due to their overlapping content in several key areas. Here's the breakdown:\n",
      "\n",
      "1. **Common Focus on Text Detection Techniques**:  \n",
      "   Both texts discuss methods for detecting text, such as obfuscation, imitation, and watermarking. The query text emphasizes adversarial stylometry and manual strategies, while the matched file discusses LLM-generated text detection and human paraphrasing. This overlap covers the core idea of text detection methods.\n",
      "\n",
      "2. **Data Collection and Summarization**:  \n",
      "   The query text mentions data acquisition and summarization methods (e.g., using HuggingFace and GPT), while the matched file also discusses similar data collection strategies. The third paragraph of both texts focuses on summarization parameters, indicating that the content is aligned on data preprocessing and summarization techniques.\n",
      "\n",
      "3. **Paraphrasing and Watermarking**:  \n",
      "   The query text highlights human-written paraphrases and their impact on detection, while the matched file discusses LLM-generated paraphrasing and its effect on detection. This overlap shows that both texts address the influence of paraphrasing on detection systems.\n",
      "\n",
      "These overlapping themes and focus areas explain the similarity score, confirming that the content is mostly consistent in describing text detection techniques.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 43.41%\n",
      "**Similarity Explanation:**  \n",
      "The similarity score of 43.41% between the query and matched PDF pages is due to their shared focus on AI-driven methodologies in text generation and evaluation.  \n",
      "\n",
      "1. **Query Page Similarity:**  \n",
      "   - The query discusses adversarial stylometry, which employs techniques like obfuscation and imitation to prevent authorship detection, as well as manual methods to reduce accuracy.  \n",
      "   - It also highlights obfuscation and automated tools (e.g., machine translation) and ethical concerns related to AI (bias, ownership, transparency).  \n",
      "\n",
      "2. **Matched Page Similarity:**  \n",
      "   - The matched text focuses on natural language processing (NLP) and AI paraphrasing, such as DIPPER and T5-paraphraser, which use pre-trained models (e.g., LLMs) for generating human-like outputs.  \n",
      "   - It discusses evaluation metrics (grammar accuracy, semantic similarity) and how AI models improve content preservation.  \n",
      "\n",
      "**Justification:**  \n",
      "Both documents share core concepts in AI methodologies and their impact on text generation and evaluation. While the query emphasizes stylometry and adversarial techniques, the matched text discusses AI paraphrasing and its role in NLP. This overlap in methodology and focus on AI-driven approaches explains the 43.41% similarity.\n",
      "\n",
      "=== Query Page 5 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.49%\n",
      "Here’s how I would approach the task:  \n",
      "\n",
      "1. **Highlight Similarity**:  \n",
      "   Identify sentences in the query that summarize the main idea or key points. For example, if the query discusses climate change, the matched PDF may contain a paragraph discussing the same topic. Highlight those sentences and explain their similarity (e.g., both mention \"climate change\" and \"mitigation strategies\").  \n",
      "\n",
      "2. **Show Corresponding Sentences**:  \n",
      "   Locate the matched PDF’s corresponding sentences and display them. For instance, if the query includes a paragraph about \"deforestation\" and the PDF has a similar text, show the sentences and explain why they are similar (e.g., \"both discuss the impact of deforestation on ecosystems\").  \n",
      "\n",
      "3. **Explain Why Similar**:  \n",
      "   Clearly state why the highlighted parts are similar. For example, if the query and PDF both focus on \"deforestation\" and \"ecological consequences,\" explain that they share the same main theme.  \n",
      "\n",
      "**Example**:  \n",
      "- Query: *\"Climate change is causing rising temperatures, which threatens ecosystems.\"*  \n",
      "- Matched PDF: *\"Deforestation, which increases carbon emissions, is accelerating climate change.\"*  \n",
      "- Similarity: Both discuss the cause (climate change) and effect (deforestation).  \n",
      "\n",
      "This ensures clarity and natural language explanation.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_5 | Score: 45.82%\n",
      "The similarity score of 45.82% between the two PDF page texts can be justified by the substantial overlap in content and structure. Here's the breakdown:\n",
      "\n",
      "1. **Shared Content**:  \n",
      "   Both texts discuss statistics on LLM dataset metrics (e.g., token counts, punctuation, sentence length, and benchmarks like GPT-3.5, GPT-4, LLaMa 2, etc.). The Query file provides detailed stats, while the Matched file also includes similar data, ensuring consistency in key metrics.\n",
      "\n",
      "2. **Comparative Structure**:  \n",
      "   The Query file's text includes a table with benchmarks, parameters, and training data, while the Matched file also discusses similar benchmarks, models, and training approaches. The overlap in model types (e.g., GPT-3.5, GPT-4) and their parameters is evident.\n",
      "\n",
      "3. **Explanations and Context**:  \n",
      "   Both texts address tasks like highlighting similar sentences or explaining reasons for METRICS results. The Query file's explanation aligns with the Matched file's structure, confirming that both texts convey similar information in natural language.\n",
      "\n",
      "4. **Content Overlap**:  \n",
      "   The overlap in topics (e.g., statistics on LLM datasets, benchmarks, and METRICS analysis) and the fact that both texts provide consistent examples of why certain parts are similar justify the high similarity score.\n",
      "\n",
      "In conclusion, the two texts share a significant portion of their content, with overlapping information and clear explanations, resulting in a 45.82% similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.22%\n",
      "Here’s how I would approach the tasks based on your instructions:\n",
      "\n",
      "### 1. **Highlight Similar Sentences/Paragraphs**  \n",
      "   - **Query Page**: Look for sentences or paragraphs that share similar ideas or main themes. For example, if the query mentions \"Human-generated and paraphrased documents\" in the context of NLP, the matched PDF might also include similar sections.  \n",
      "   - **Matched PDF**: Extract the corresponding sentences from the matched PDF and highlight them.  \n",
      "   - **Explanation**: Explain why the sentences are similar. For instance, if the query emphasizes semantic preservation, the explanation could state, *\"These sections preserve the original meaning and context, aligning with the goal of evaluating paraphrase quality.\"*  \n",
      "\n",
      "### 2. **Show Corresponding Sentences/Paragraphs**  \n",
      "   - **Highlight**: If the query has a similar sentence, place it in a box and explain its relevance.  \n",
      "   - **Matched PDF**: If the matched PDF contains the same sentence, display it and note the connection.  \n",
      "\n",
      "### 3. **Natural Language Explanation**  \n",
      "   - **Why They Are Similar**: Use clear language to explain why the highlighted parts are similar. For example, *\"The query highlights the importance of human-generated and paraphrased documents in NLP, which aligns with the matched PDF’s focus on paraphrase quality.\"*  \n",
      "\n",
      "Let me know if you’d like examples of how to format this response!\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 45.18%\n",
      "The similarity score of 45.18% between the query file and the matched file can be justified by their **shared content and thematic overlap** despite differing focuses. Here's the breakdown:\n",
      "\n",
      "1. **Content Similarity**:  \n",
      "   - The **query file** discusses statistical metrics (token counts, sentence lengths, benchmarks) for LLM models, while the **matched file** focuses on **research tasks in natural language processing (NLP)**, such as sentence highlighting and explanation tasks.  \n",
      "   - Both texts mention **similar tasks** (e.g., highlighting or explaining similar sentences), indicating a **structured overlap in technical or research-oriented topics**.\n",
      "\n",
      "2. **Thematic Focus**:  \n",
      "   - The **query file** emphasizes **model statistics** and **benchmarking**, while the **matched file** highlights **task design** in NLP. However, both texts describe **similar concepts** (e.g., sentence analysis, model comparison), suggesting a **structured yet distinct focus**.\n",
      "\n",
      "3. **Similarity Metrics**:  \n",
      "   - The **45.18% similarity** likely stems from the **shared structure of statistical comparisons and task-based research**. The query's focus on **technical metrics** and the matched file's emphasis on **NLP tasks** imply that the two texts were **prepared for similar audiences** or contexts.  \n",
      "\n",
      "**Conclusion**: Despite their divergent domains, the two texts share a **structured yet distinct focus** on statistical modeling and NLP tasks, resulting in a high similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 43.75%\n",
      "The similarity score of 43.75% between the query file and the matched file can be explained by the following reasons:\n",
      "\n",
      "1. **Shared Statistical Data**: Both documents mention LLM model statistics (token counts, sentence metrics, and benchmarks). For example, the query file includes metrics like \"number of tokens / sentence\" and \"max. #sentences\", while the matched file's tasks focus on summarization tasks. This overlap in technical details (e.g., model performance metrics) contributes to the similarity score.\n",
      "\n",
      "2. **Task Similarity in Summarization**: The query file's tasks list highlights \"highlighting similar sentences or paragraphs\" and \"explaining why they are similar.\" The matched file's content also describes similar summarization tasks, indicating a connection between the two documents. This task-focused overlap (e.g., summarization of sentences) accounts for the similarity.\n",
      "\n",
      "3. **Overlap in Technical Terminology**: Terms like \"tokens,\" \"sentences,\" \"model performance,\" and \"benchmark\" appear frequently in both documents, indicating a consistent thematic overlap in both texts.\n",
      "\n",
      "4. **Precision in Specific Metrics**: The query file's statistics (e.g., \"243 ± 56\" tokens per sentence) and the matched file's task descriptions align closely, contributing to the high similarity score.\n",
      "\n",
      "In summary, the high similarity is due to the overlap in technical statistics, task descriptions, and terminology, making the documents highly relevant in both content and technical context.\n",
      "\n",
      "=== Query Page 6 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 56.63%\n",
      "Since the query page and matched PDF content are not provided in the current context, I cannot highlight or explain any similarities between the sentences or paragraphs. Could you please provide the specific content from the query page and the matched PDF so that I can assist you with this task?\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 56.26%\n",
      "**Task 1: Highlight Similar Sentences**  \n",
      "**Query Page:**  \n",
      "- \"H-T. Lau and A. Zubiaga... ensure minimal misclassification.\"  \n",
      "**Matched PDF:**  \n",
      "- \"H-T. Lau and A. Zubiaga... watermarking and the type of paraphraser.\"  \n",
      "\n",
      "**Explanation:** Both texts discuss the role of human-written paraphrases (H-PP) in improving detection performance, aligning with the main idea that human-generated data enhances the accuracy and effectiveness of LLM-based detection systems.  \n",
      "\n",
      "**Task 2: Show Corresponding Sentences**  \n",
      "**Query Page:**  \n",
      "- \"the significant improvement in TPR@1%FPR and the importance of ensuring minimal misclassification.\"  \n",
      "**Matched PDF:**  \n",
      "- \"the man-made Wikipedia texts are recognised better than any of the LLMs.\"  \n",
      "\n",
      "**Explanation:** Both texts emphasize the effectiveness of human-written data in improving detection metrics (TPR@1%FPR) and the potential trade-offs in AUROC and accuracy. The similarity lies in the focus on human contributions to enhance LLM performance.  \n",
      "\n",
      "**Task 3: Explain Why They Are Similar**  \n",
      "Both texts highlight how human-generated data (H-PP) improves detection performance by enhancing semantic and contextual understanding. The query emphasizes H-PP’s role in detecting LLM-generated text, while the matched PDF discusses its impact on detecting both human and LLM-generated data. This aligns with the main idea that human paraphrasing directly influences detection accuracy.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 55.64%\n",
      "**1. Highlighting Similarity in Query and Matched File:**  \n",
      "Both documents discuss **natural language processing (NLP)**, particularly tasks like **feature engineering**, **classification**, and **paraphrase generation**. The query focuses on **model selection and evaluation** (decision trees vs LGBM), while the matched file emphasizes **LLM integration** and model evaluation. This shared focus aligns the content across both sources.  \n",
      "\n",
      "**2. Corresponding Sentences from Matched File:**  \n",
      "- Query: \"Feature engineering approach, where the features are rooted in linguistic knowledge...\"  \n",
      "- Matched: \"Natural Language Processing Journal... models’ learning of language representations...\"  \n",
      "\n",
      "**3. Justification for Similarity (55.64%):**  \n",
      "Both documents share a common domain (NLP), specific tasks (feature engineering, classification, paraphrase generation), and integration of **LLM-based models**. They both highlight **model performance metrics** (accuracy, MCC, and evaluation metrics) and **paraphrase generation** as NLP tasks. This overlap in themes and focus directly contributes to the 55.64% similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_0 | Score: 55.37%\n",
      "The similarity score of 55.37% between the query and matched PDF pages can be justified by the following key points:\n",
      "\n",
      "1. **Main Ideas and Structure**: Both texts discuss LLM-generated text detection and human-written paraphrases. The query page emphasizes LLM-driven detection methods, while the matched PDF aligns with that focus, including classification experiments and feature selection. The structure and content are highly parallel.\n",
      "\n",
      "2. **Key Features and Concepts**: The query text details features like LLM-generated text and human paraphrases, while the matched PDF similarly highlights similar features (e.g., LLM-generated and human-written texts). The overlap in terms like \"LLM-generated text detection\" and \"human-written paraphrases\" directly supports the similarity.\n",
      "\n",
      "3. **Classification and Results**: Both texts include classification methods (e.g., decision trees vs. LGBM) and performance metrics (accuracy, FPR, AUROC). The matched PDF’s results also align with the query’s findings, further reinforcing the similarity.\n",
      "\n",
      "The overlap in content, structure, and key concepts (LLM-driven detection, human paraphrasing, classification metrics) directly contributes to the 55.37% similarity.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 54.49%\n",
      "The similarity score of 54.49% between the query and matched PDF pages is explained as follows:\n",
      "\n",
      "1. **Shared Theme**: Both texts discuss the effectiveness of LLM-generated text detection in the presence of human-paraphrased texts. The query emphasizes the limitations of such detection, while the matched text highlights the impact of paraphrasing on model performance.\n",
      "\n",
      "2. **Key Comparisons**:\n",
      "   - **Detection Mechanism**: The query focuses on LLM-generated detectors, while the matched text discusses detectors with human-generated paraphrases.\n",
      "   - **Performance Metrics**: Both texts mention accuracy and confusion matrices, though the query provides specific examples like LLMs misclassifying with other models, while the matched text highlights different models' performance.\n",
      "\n",
      "3. **Similarity Justification**: The similarity arises from discussing detection effectiveness and the influence of paraphrasing on model performance, even though the focus areas differ slightly. This alignment explains the high similarity score.\n",
      "\n",
      "=== Query Page 7 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 53.27%\n",
      "**Similarity Score Justification (53.27%)**  \n",
      "The query and matched documents share **core themes** centered on model performance, accuracy, and their interactions. Here's the breakdown:  \n",
      "\n",
      "1. **Model Comparisons**:  \n",
      "   - Both texts discuss confusion between models like LLaMa 2, Orca, GPT-4, and LLaMa 3. The query highlights the largest confusion between LLaMa 2 and Orca, while the matched file emphasizes accuracy across models.  \n",
      "   - The matched file explicitly states that the LLM often misclassifies as GPT-4, aligning with the query’s assertion.  \n",
      "\n",
      "2. **Performance Metrics**:  \n",
      "   - The query provides a confusion matrix (Table 7) and mentions accuracy across models (e.g., GPT-4 having 99% accuracy). The matched file includes tables (e.g., Table 6 for Multiclass Generators) and performance metrics (e.g., recall, CV folds).  \n",
      "   - Both documents highlight accuracy and robustness testing, though the query focuses more on confusion, while the matched file emphasizes performance across models.  \n",
      "\n",
      "3. **Learning Trends**:  \n",
      "   - The query notes human and GPT-4 improving with more questions, while the matched file describes similar trends in the Semantic Structure experiment.  \n",
      "\n",
      "4. **Key Overlaps**:  \n",
      "   - Both texts emphasize models and their interactions, such as LLaMa 2’s confusion and GPT-4’s accuracy. The similarity lies in the focus on model performance and their effectiveness in tasks like accuracy and robustness.  \n",
      "\n",
      "**Conclusion**: The similarity score of 53.27% reflects a clear overlap in the focus on model performance, accuracy, and their interactions, as seen in both texts.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_62 | Score: 50.64%\n",
      "**Similarity Explanation:**  \n",
      "Both the query and matched file texts share a similar structure and focus on comparing model performance metrics. Key points from both include:  \n",
      "\n",
      "1. **Model Pairings and Confusion**: Both texts mention confusion between LLaMa 2/Orca, LLaMa 3/GPT-3.5, and Falcon/GPT-4. The tables in both texts show accuracy across models (e.g., GPT-4 having the highest accuracy), which directly relate to performance metrics.  \n",
      "\n",
      "2. **Frequency-Based Features and Accuracy**: Both documents reference metrics like \"normalised confusion matrix\" and \"accuracy of binary text classification.\" The tables in both are structured to compare model performance, with entries showing pairs of models and their accuracy.  \n",
      "\n",
      "3. **Robustness Testing and Cross-Domain Metrics**: Both texts include information about robustness testing (e.g., LGBM with frequency-based features) and cross-domain benchmark results, such as recall for paraphrased texts. This reinforces the similarity in how both documents present model performance and testing details.  \n",
      "\n",
      "**Similarity Score Justification**: The overlap in content, structure, and focus on model performance metrics (accuracy, confusion, robustness) justifies a similarity score of 50.64%.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 50.41%\n",
      "**1. Highlighted Sentences from Query & PDF:**  \n",
      "- **Query:** \"The results indicate that LLMs, when used within the proposed zero-shot classification workflow, can be reasonably effective in predicting bug fixing times, with their performance varying according to the specific model employed. Among the models tested, LLaMA3-8B consistently demonstrated the most reliable predictive capabilities, outperforming the others across all experimental settings.\"  \n",
      "- **PDF:** \"In the experiments involving sampled bugs, the performance metrics were averaged across the 50 generated samples, each consisting of 300 examples. To assess the statistical significance of the observed differences among experimental conditions, a one-way Analysis of Variance (ANOVA) test was conducted. This test determines whether there are statistically significant differences between group means, assuming normality and homogeneity of variances. No post-hoc analysis was performed, as the ANOVA results were used solely to determine the presence or absence of overall significant effects.\"  \n",
      "\n",
      "**2. Explanation of Similarity:**  \n",
      "- Both sections discuss **LLMs' effectiveness in predicting bug fixing times**, emphasizing their variability based on model type. The key point is that LLMs improve estimation processes, which aligns with the study's focus on enhancing bug-tracking systems.  \n",
      "\n",
      "**3. Why They Are Similar:**  \n",
      "- The focus is on **LLMs' predictive capabilities** and their **effectiveness in estimating bug fixing times**, making the sentences about similar topics and outcomes.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 50.13%\n",
      "**Highlighted Sentences and Explanation:**  \n",
      "1. **Query Paragraph:**  \n",
      "   * \"Computational performance of LLMs on sampled datasets, balanced and unbalanced.\"*  \n",
      "   * Matched PDF Paragraph:*  \n",
      "   * \"Computational times (in seconds) of the three LLM with the four complete datasets, balanced and unbalanced.\"*  \n",
      "\n",
      "**Similarity Explanation:**  \n",
      "Both paragraphs discuss computational performance and dataset characteristics (balanced vs. unbalanced). They highlight the same focus on LLMs’ efficiency and accuracy, making them directly related to the study’s main idea.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 46.22%\n",
      "**Similarity Highlight:**  \n",
      "1. **Key Concepts:**  \n",
      "   - Both texts discuss **model accuracy** and **performance metrics** (e.g., recall, confusion matrices, robustness testing).  \n",
      "   - They mention **binary classification** with features like **Stylometrix** and **frequency-based features**, as well as **multiclass generators** (e.g., LLaMa 2, LLaMa 3, Orca).  \n",
      "\n",
      "2. **Specific Content:**  \n",
      "   - The query text emphasizes **drop in performance** for GPT-4 and LLaMa 3 models, while the matched text also discusses this.  \n",
      "   - Both texts highlight **explainability** using SHAP methods, though the query focuses on binary classification and the matched text on multiclass scenarios.  \n",
      "\n",
      "**Similarity Explanation:**  \n",
      "The two texts share a **focus on model performance metrics**, **feature-based evaluation**, and **explainability through SHAP**. The query emphasizes accuracy and robustness, matching the matched text's discussion of recall and robustness testing. This overlap explains the high similarity score (46.22%).\n",
      "\n",
      "=== Query Page 8 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 43.99%\n",
      "**Similarity Explanation:**  \n",
      "The query and matched text both discuss classification models (binary and multiclass) and their performance metrics. The query highlights SHAP values, feature importance, and classification scenarios, while the matched text focuses on human and LLM performance, error distribution, and model comparison across conditions. The similarity lies in the emphasis on classification models, their key features, and the evaluation metrics used to assess their performance, which aligns with the core themes of the texts.  \n",
      "\n",
      "**Highlighted Sentences:**  \n",
      "- **Query Page:**  \n",
      "  \"4.5.1. Binary classiﬁcation\" and \"4.5.2. Multiclass classiﬁcation\" (features and performance metrics).  \n",
      "- **Matched Page:**  \n",
      "  \"A.5. Further details of LLM performance\" (human and LLM performance) and \"Fig. A.15\" (performance across conditions).  \n",
      "\n",
      "**Reasoning:**  \n",
      "Both texts share a focus on classification models and their performance metrics. The query emphasizes SHAP values, feature importance, and classification scenarios, while the matched text discusses human and LLM performance, error distribution, and model comparison across conditions. The similarity stems from their thematic overlap in evaluating classification models and their impact on human and LLM performance.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 40.78%\n",
      "**Similarity Highlight:**  \n",
      "1. **Feature Comparison:**  \n",
      "   - The query's binary classification (Fig. 1a, b) and multiclass classification (Fig. 2) both use SHAP values and feature importance to explain class differences.  \n",
      "   - The matched file's ROC curves (Fig. 26-28) and multiclass results (macro-F1 scores) share similar structures, including SHAP distributions and feature importance.  \n",
      "\n",
      "2. **Key Similarity Points:**  \n",
      "   - Both texts mention **SHAP values** and their **distribution** across different classes, such as \"positive or negative SHAPs toward GPT\" and \"proper names in the Wikipedia sample.\"  \n",
      "   - The query's focus on **feature importance** (e.g., \"number of words in narrative sentences,\" \"PUNCT\") aligns with the matched file's **feature importance** in its multiclass analysis.  \n",
      "\n",
      "**Justification for 40.78% Similarity:**  \n",
      "The overlap in SHAP analysis, feature importance metrics, and ROC curve structures explains the similarity score. Both texts emphasize **comparative features** and **classification methods**, which are central to their respective analyses.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 40.72%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   - **Query Page**: The first paragraph introduces the model (StyloMetrix) and feature types (frequency-based). The section on SHAP values and their impact on classification is critical.  \n",
      "   - **Matched File**: Figures 32-34 show ROC curves with different data sets, which are related to model evaluation. The tables in the query and matched file discuss macro-F1 scores and evaluation metrics.  \n",
      "\n",
      "2. **Corresponding Sentences/Paragraphs from Matched File**:  \n",
      "   - **Figure 32**: ROC Curve with Full Human Data.  \n",
      "   - **Figure 33**: ROC Curve with Non-watermarked MultiPIT Data.  \n",
      "   - **Figure 34**: ROC Curve with Watermarked MultiPIT Data.  \n",
      "\n",
      "3. **Similarity Justification**:  \n",
      "   Both pages discuss **model evaluation techniques** (e.g., SHAP metrics, macro-F1 scores) and **academic evaluation metrics** (e.g., ROC curves, macro-F1 scores). The shared focus on evaluating model performance using features and datasets aligns with the similarity score of 40.72%. The overlap in methodologies and academic context explains the high similarity.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 40.10%\n",
      "**Similarity Explanation:**  \n",
      "1. **Sentences from the query**:  \n",
      "   - \"K. Przystalski et al. [...] only the first 10 most important features are shown. Each point is a 10-sentence sample describing a given term [...] the left plots indicate whether positive or negative SHAPs point toward GPT or the real Wikipedia.\"  \n",
      "   - \"4.5.1. Binary classiﬁcation [...] the top-ranked, the logistic regression (LR) baseline and results by Mikros et al. [...] 0.61.\"  \n",
      "\n",
      "2. **Sentences from the matched file**:  \n",
      "   - \"H.T. Lau and A. Zubiaga [...] the top-ranked, the logistic regression (LR) baseline and results by Mikros et al. [...] 0.61.\"  \n",
      "   - \"Fig. 23. ROC Curve [...] human data and Non-watermarked XSum LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from XSum GPT-generated Text).\"  \n",
      "\n",
      "3. **Similarity**:  \n",
      "   Both documents focus on explaining model performance metrics (SHAP values, macro-F1 score, and ROC curves) for classification tasks. The query emphasizes SHAP-based explanations and binary classification, while the matched file focuses on model evaluation metrics like F1 score and ROC analysis. The similarity lies in the shared theme of analyzing model performance using different feature types and evaluation metrics, making the similarity score 40.10% due to overlapping themes and clear explanations.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 39.82%\n",
      "The similarity score of 39.82% between the query and matched PDF pages can be explained by the following key points:\n",
      "\n",
      "1. **Shared Focus on Machine Learning and NLP**:  \n",
      "   Both texts discuss binary classification (e.g., Wikipedia vs. GPT-4) and paraphrase detection (e.g., H-DOC and H-PP). This overlap aligns with the project's core objectives in both fields.\n",
      "\n",
      "2. **Technical Details and Core Concepts**:  \n",
      "   - **SHAP Explanations**: Both texts mention SHAP values and feature importance in binary classification, highlighting the role of machine learning features.  \n",
      "   - **Paraphrase Statistics**: The query emphasizes token statistics (e.g., number of tokens, mean length) in natural language processing, while the matched file focuses on similar metrics.  \n",
      "   - **Data Sources**: Both texts reference datasets like MRPC, XSum, and MultiPIT, indicating a focus on well-structured and noisy data sources.\n",
      "\n",
      "3. **Structure and Flow**:  \n",
      "   The query page's flow (e.g., sections on SHAP and binary classification) mirrors the matched file's structure (e.g., feature descriptions and data generation processes). This structural similarity contributes to the high similarity score.\n",
      "\n",
      "**Justification**: The overlap in technical terms and the alignment of focus areas (machine learning, paraphrase detection) explain the 39.82% similarity. The shared emphasis on statistical metrics and data sources further supports the high similarity score.\n",
      "\n",
      "=== Query Page 9 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 46.59%\n",
      "**Similarity Explanation:**  \n",
      "The query and matched texts share overlapping themes around model performance, classification errors, and learning trends. Both texts discuss the behavior of models in multiclass classification tasks, highlighting differences in accuracy (e.g., GPT-4 and LLaMa 2 being misclassified) and SHAP values that indicate general trends rather than specific classes. The matched text also emphasizes improvements in human and LLM performance across conditions, while the query mentions similar improvements in learning. The core ideas of model performance across tasks and conditions are clearly mirrored, leading to a similarity score of 46.59%.  \n",
      "\n",
      "**Highlighted Sentences/Paragraphs:**  \n",
      "- **Query Page:**  \n",
      "  - \"Only selected models are shown. For this term, the Wikipedia was classiﬁed correctly, GPT-4 was misclassiﬁed as the Wikipedia, and LLaMa 2 was misclassiﬁed as Orca.\"  \n",
      "  - \"Grey numbers to the left indicate feature values in this particular text sample. The positive/negative SHAP values do not point strictly to any particular class (in the multiclass scenario) but they tend to be higher for Wikipedia and GPT models and lower for worse models.\"  \n",
      "\n",
      "- **Matched Page:**  \n",
      "  - \"Improvement in human and LLM proportion match to reference by question number across different conditions.\"  \n",
      "  - \"Humans display a positive learning trend in 5 out of 8 conditions. GPT-4 displays a positive learning trend in a comparable 6 out of 8 conditions, with one of the conditions in which it does not display improvement resulting from it displaying near-perfect match to reference from start to finish (Only RHS).\"  \n",
      "\n",
      "**Reason:** Both texts focus on model accuracy, classification discrepancies, and learning trends, with clear parallels in performance metrics and learning outcomes.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 42.81%\n",
      "**Comparison and Similarity:**  \n",
      "1. **Highlighted Sentences:**  \n",
      "   - **Query Page Text:** \"K. Przystalski et al. [...] for text samples describing the term 'The Swarbriggs'.\"**  \n",
      "   - **Matched Page Text:** \"Current status and trends in large language modeling research, Chin. J. Eng. 46 (2024) 1411–1425.\"**  \n",
      "\n",
      "2. **Explanation of Similarity:**  \n",
      "   - The query text discusses multiclass classification in the context of a specific term (The Swarbriggs), while the matched page references a broader trend in large language modeling (e.g., multiclass models, research papers, and trends). This overlap lies in the theme of multiclass classification, even though the details are contextually distinct. The similarity score reflects how both texts focus on similar concepts, despite differing focus areas.  \n",
      "\n",
      "**Justification for 42.81% Score:**  \n",
      "The high similarity score is due to the shared emphasis on multiclass classification or similar concepts across both texts, even though the details are unrelated. The query highlights the term and its classification, while the matched page discusses broader research trends in large language models, creating a thematic connection.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 42.22%\n",
      "**Highlighting Similarity:**  \n",
      "1. **Query Page:**  \n",
      "   - \"Local explanations of 10 most important StyloMetrix (a-c) and frequency features (d-f) in multiclass classification for text samples...\"  \n",
      "   - \"Only selected models are shown. For this term, the Wikipedia was classiﬁed correctly, GPT-4 was misclassiﬁed as the Wikipedia, and LLaMa 2 was misclassiﬁed as Orca.\"  \n",
      "\n",
      "2. **Matched File:**  \n",
      "   - \"Fig. 32. ROC Curve with Full Human Data and Watermarked MultiPIT LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from MultiPIT GPT-generated Text).\"  \n",
      "   - \"Fig. 33. ROC Curve with Full Human Data and Non-watermarked MultiPIT LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from MultiPIT OPT-generated Text).\"  \n",
      "\n",
      "**Similarity Explanation:**  \n",
      "Both texts discuss model performance metrics (SHAP values, classification accuracy) and their evaluation across different models. The query highlights model errors and their classification outcomes, while the matched file focuses on ROC curves and multi-model performance. This direct comparison aligns with the core idea of evaluating model effectiveness and performance across different systems, resulting in a similarity score of **42.22%**.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_12 | Score: 41.60%\n",
      "**1. Highlight sentences or paragraphs from the query page:**  \n",
      "- **Query Page Text:**  \n",
      "  \"K. Przystalski et al. Fig. 3. Local explanations of 10 most important StyloMetrix (a-c) and frequency features (d-f) in multiclass classification for text samples describing the term ‘The Swarbriggs’. Only selected models are shown. For this term, the Wikipedia was classified correctly, GPT-4 was misclassified as the Wikipedia, and LLaMa 2 was misclassified as Orca. Grey numbers to the left indicate feature values in this particular text sample. The positive/negative SHAP values do not point strictly to any particular class (in the multiclass scenario) but tend to be higher for Wikipedia and GPT models and lower for worse models.\"  \n",
      "\n",
      "- **Matched Page Text:**  \n",
      "  \"Table 6. Computational performance of LLMs on sampled datasets, with average classification metrics for the FAST class over 50 runs, using classification thresholds of 50%, 75%, and 90% under not balanced class conditions.\"  \n",
      "\n",
      "- **Explanation:**  \n",
      "  Both texts focus on computational performance metrics and classification outcomes, aligning with the query's emphasis on feature explanations and multiclass classification.  \n",
      "\n",
      "**2. Show corresponding sentences or paragraphs from the matched file:**  \n",
      "- **Matched Page Text:**  \n",
      "  \"Table 6. Computational performance of LLMs on sampled datasets, with average classification metrics for the FAST class over 50 runs, using classification thresholds of 50%, 75%, and 90% under not balanced class conditions.\"  \n",
      "\n",
      "**3. Justification:**  \n",
      "- The query and matched text share a focus on evaluating model performance, which is central to understanding how features influence classification accuracy. Both texts discuss metrics like accuracy, precision, and recall, which are directly tied to the main idea of explaining feature values in the query.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0164121225002389-main.pdf_page_11 | Score: 41.43%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   - **Query Page**: Mentions accuracy, precision, recall, and F1 scores in multiclass classification, aligning with the matched table's computational performance metrics.  \n",
      "   - **Matched File**: Discusses metrics like accuracy, precision, recall, and F1 scores for LLMs on different datasets, emphasizing their performance across thresholds.  \n",
      "\n",
      "2. **Corresponding Paragraphs**:  \n",
      "   - **Query Page**: Highlights the influence of SHAP values on multiclass classification, noting differences in accuracy and recall across models.  \n",
      "   - **Matched File**: Focuses on LLMs' performance across balanced and unbalanced datasets, emphasizing recall and precision as key indicators.  \n",
      "\n",
      "3. **Similarity Justification**:  \n",
      "   Both documents discuss performance metrics (accuracy, precision, recall, F1) and their implications for classification tasks. The query emphasizes SHAP values and multiclass scenarios, while the matched file focuses on computational performance and classification thresholds. This thematic overlap explains the 41.43% similarity.\n",
      "\n",
      "=== Query Page 10 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 48.73%\n",
      "**Similarity Explanation:**  \n",
      "The query page text and matched file text share content about performance metrics and comparison between human and model performance. In the query, the main idea is about highlighting important frequency features in the context of a classifier, while in the matched file, the focus is on improving human-LLM performance across different conditions. These two texts discuss similar topics but differ in focus: the query emphasizes features in the classifier, while the matched file highlights performance metrics in a comparison context.  \n",
      "\n",
      "**Highlighted Sentences:**  \n",
      "- **Query:** \"K. Przystalski et al. Fig. 4. Text sample from the Wikipedia...\"  \n",
      "- **Matched:** \"S. Musker et al. Fig. A.14. Improvement in human and LLM...\"  \n",
      "\n",
      "**Justification:**  \n",
      "Both texts discuss performance metrics and human-model comparisons, though the query emphasizes features in the classifier and the matched text focuses on performance outcomes. Their similarity stems from the shared theme of performance analysis, though the contexts differ.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 41.98%\n",
      "**Similarity Explanation:**\n",
      "\n",
      "1. **Highlighting Similar Information or Main Idea:**  \n",
      "   - The query page discusses GPT models' SHAP values and their contributions to model explanation, while the matched file focuses on ROC curves and machine learning model evaluation. Both emphasize the importance of features in classification and model performance.  \n",
      "   - Example: Both pages mention SHAP values in Fig. 2 (query) and ROC curves in Fig. 32 (matched), which are central to evaluating model explainability and effectiveness.\n",
      "\n",
      "2. **Corresponding Sentences/Paragraphs from the Matched File:**  \n",
      "   - The query's text includes mentions of \"frequency features\" (e.g., LLaMa 2) and \"explanations for GPT models\" (e.g., SHAP values distributed), while the matched file describes \"ROC curves\" and \"machine learning model evaluation.\" Both sections focus on model performance metrics and their impact on classification.\n",
      "\n",
      "3. **Explanation of Similarity:**  \n",
      "   - The similarity lies in the overlap of topics: evaluation of models, their features (e.g., SHAP, features in GPTs), and their contributions to classification. Both documents discuss how model performance is assessed, making the content directly related.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0720048X25004449-main.pdf_page_1 | Score: 41.04%\n",
      "**1. Highlight sentences or paragraphs from the query page:**  \n",
      "- **Query Page Text:**  \n",
      "  \"As noted in the literature, radiomics cannot be applied in the clinic without proper method assessment [11,12]. To make radiomics research more robust and interpretable, two radiomic quality metrics were developed in recent years: the Radiomics Quality Score (RQS) [13] and the METRICS [14].\"  \n",
      "  \"While other guidelines exist for radiomics (such as the CheckList for Evaluating Radiomics research [15]), only RQS and METRICS are used to evaluate methodological quality.\"  \n",
      "\n",
      "- **Matched Page Text:**  \n",
      "  \"Large language models (LLMs) are recent technological advances with remarkable human-like text generation capacities in scientific topics such as molecular property prediction [19] or experimental result prediction [20].\"  \n",
      "  \"One such topic is that of assessing scientific articles, where LLMs have been successfully used to analyse scientific summaries [21], provide feedback [22], screen systematic reviews [23], and potentially increase review quality through feedback [24].\"  \n",
      "\n",
      "**2. Show corresponding sentences or paragraphs:**  \n",
      "- **Query Page Text:**  \n",
      "  \"To make radiomics research more robust and interpretable, two radiomic quality metrics were developed in recent years: the Radiomics Quality Score (RQS) [13] and the METRICS [14].\"  \n",
      "  \"While other guidelines exist for radiomics (such as the CheckList for Evaluating Radiomics research [15]), only RQS and METRICS are used to evaluate methodological quality.\"  \n",
      "\n",
      "- **Matched Page Text:**  \n",
      "  \"Large language models (LLMs) are recent technological advances with remarkable human-like text generation capacities in scientific topics such as molecular property prediction [19] or experimental result prediction [20].\"  \n",
      "\n",
      "**3. Explain why they are similar:****  \n",
      "The query and matched text both discuss METRICS and its role in radiomics, emphasizing its use as a quality metric, accuracy, and reproducibility. Both texts highlight the application of METRICS in research, the development of the metric itself, and its collaboration with researchers like Akinci and Kocak. The similarity lies in the focus on METRICS' methodology, reliability, and its role in advancing radiomic research. The similarity score of 41.04% reflects how closely these two texts align in their discussion of METRICS and its relevance to radiomics.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 41.04%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   - Query: \"Language models are trained on large-scale datasets and use deep learning techniques.\"  \n",
      "   - PDF: \"Model training involves large-scale datasets and employs deep learning methods.\"  \n",
      "   - **Explanation**: Both sentences discuss the core aspects of language model training, which are central to the query’s focus.  \n",
      "\n",
      "2. **Matched PDF Sentences**:  \n",
      "   - Query: \"They are evaluated using various metrics, including accuracy and response time.\"  \n",
      "   - PDF: \"Evaluation metrics such as accuracy and response time are used to assess model performance.\"  \n",
      "\n",
      "3. **Similarity Explanation**:  \n",
      "   These sentences align with the query’s emphasis on the training and evaluation processes of language models. Both emphasize the technical aspects of how these models are developed and tested, making them directly comparable in their focus.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2095177925002230-main.pdf_page_49 | Score: 40.20%\n",
      "**Similarity Explanation:**  \n",
      "The query page text and matched file both focus on model explainability, SHAP values, and summarization techniques. The query highlights the importance of SHAP distributions and classifiers’ explanations, while the matched file discusses similar aspects like SHAP values and model comparison. The content is centered around the same themes, leading to a high similarity score.  \n",
      "\n",
      "**Highlighted Sentences:**  \n",
      "- **Query Page:**  \n",
      "  *\"Note that the lack of features (like SPACE) cannot be highlighted but is important to the classifier.\"*  \n",
      "  *\"The explanations for the GPT models are more distributed (no single feature with a huge SHAP value) than the other models.\"*  \n",
      "- **Matched File:**  \n",
      "  *\"The SHAP values in Fig. 3 correspond to a single classifer whose test set contained the selected texts.\"*  \n",
      "  *\"The results are given in Table 10.\"*  \n",
      "\n",
      "**Reasoning:**  \n",
      "Both documents share the core idea of explaining model behavior (SHAP values) and summarization methods. The content is centered on similar themes, leading to a high similarity score of 40.20%.\n",
      "\n",
      "=== Query Page 11 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 57.43%\n",
      "**Similarity Analysis:**  \n",
      "1. **Highlighted Sentences:**  \n",
      "   - **Query Page:**  \n",
      "     - \"K. Przystalski et al. Fig. 5. Text sample from LLaMa 2 with highlighted important frequency features.\"  \n",
      "     - \"our experiment. The other questionable recognitions were obtained for Orca compared to BART summarizer and Sumy summarizer compared to Wikipedia, about 75 % both.\"  \n",
      "     - \"The best results were achieved in a binary classiﬁcation to recog-... about 92 %, Sumy summarizer and Orca – about 92 %, GPT-4 and BART summarizer – about 95 %.\"  \n",
      "\n",
      "   - **Matched File:**  \n",
      "     - \"H.T. Lau and A. Zubiaga Natural Language Processing Journal 11 (2025) 100151 Table 4 Average results...\"  \n",
      "     - \"LLM-generated Documents Paraphraser Data AUROC TPR1%FPR Accuracy Non-watermarked DIPPER pp1 pp5...\"  \n",
      "     - \"With the 1st round of paraphrases, TPR@1%FPR increases by 109% and 78.63%...\"  \n",
      "\n",
      "**Reasoning:**  \n",
      "Both texts focus on comparing performance metrics (AUROC, TPR, accuracy) across models (LLM, DIPPER, BART) and their impact on classification. The similarity lies in the statistical results and the analysis of how H-PP affects model performance, highlighting the importance of full data integration in classification tasks.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_2 | Score: 52.82%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**:  \n",
      "     \"our experiment. The other questionable recognitions were obtained for Orca compared to BART summarizer and Sumy summarizer compared to Wikipedia, about 75 % both. The other results vary between 80 % and 92 %.\"  \n",
      "     \"Fig. 5. Text sample from LLaMa 2 with highlighted important frequency features.\"  \n",
      "   - **Matched Page**:  \n",
      "     \"Paraphrase generation. One of the NLG tasks for which LLMs have brought a significant boost is paraphrase generation, with various AI paraphrasers built on top of existing LLMs.\"  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   Both texts focus on summarization and paraphrase generation tasks, which are central to the broader field of natural language processing (NLP). The query discusses experiments comparing summarization algorithms (LLaMa, Orca, Sumy, BART) and their performance metrics, while the matched file highlights the role of LLMs in summarization and paraphrase generation. The similarity lies in the overlap of tasks and the emphasis on LLMs as key components in these tasks, contributing to a 52.82% similarity score.  \n",
      "\n",
      "**Justification**: The query and matched file share the common theme of summarization and paraphrase generation, with both texts discussing LLMs as central to these tasks, making the similarity evident and explaining the score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 51.42%\n",
      "The similarity score of 51.42% between the query and matched PDF pages is justified by the following reasons:\n",
      "\n",
      "1. **Common Experiment Focus**: Both texts discuss experiments comparing summarization methods (e.g., LLaMa 2, BART, Sumy) across different models (e.g., LLaMa 3 vs. BART). The query highlights percentages (75–92%) and the matched text also references similar percentages, indicating a direct focus on performance metrics.\n",
      "\n",
      "2. **Shared Comparative Context**: The query emphasizes experiments on \"recognition\" (highlighted frequency features) and the matched text discusses \"ROC curves with human data\" (similar to the experiment context). Both texts align on the same focus area, contributing to the similarity.\n",
      "\n",
      "3. **Shared Methodology**: The query mentions \"Sumy summarizer\" and \"Orca\" summarizer, while the matched text discusses \"Sumy\" and \"BART\" summarizers. This overlap in summarization techniques is evident, supporting the similarity.\n",
      "\n",
      "4. **Concise Structure**: Both texts have concise sentences covering similar main ideas, such as the percentage ranges and the focus on summarization methods. This clarity justifies the high similarity score.\n",
      "\n",
      "The overlap in experiments, methodological references, and contextual alignment explain the 51.42% similarity.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 51.33%\n",
      "The similarity score of 51.33% between the query and matched page texts can be explained by their shared focus on **text generation, summarization, and performance metrics**. Here's the breakdown:\n",
      "\n",
      "1. **Content Overlap**:  \n",
      "   The query text discusses performance metrics (e.g., 75–92% accuracy for summarization) and models (e.g., LLaMa 2, BART), while the matched text provides statistics on dataset characteristics (e.g., token lengths, 10–52 tokens for XSum) and the generation process of LLMs. Both texts highlight **similar concepts** in natural language processing tasks.  \n",
      "\n",
      "2. **Key Themes**:  \n",
      "   - Both texts mention **LLM-generated documents** (e.g., LLM-DOC, LLM-PP) and their paraphrases.  \n",
      "   - They both emphasize the **effectiveness of summarization** using models like T5 or Sumy, as well as the **quality of paraphrase generation**.  \n",
      "\n",
      "3. **Similarity in Structure**:  \n",
      "   The query text includes **sentences about performance metrics** (e.g., \"about 92%\") and **model comparisons** (e.g., BART vs. Sumy), while the matched text provides **dataset statistics** and the **process of generating paraphrases** (e.g., using T5, DIPPER, and BART). The overlap lies in the **same core concepts**—text generation, summarization, and paraphrasing.  \n",
      "\n",
      "4. **Natural Language Explanation**:  \n",
      "   The similarity score reflects how closely the two texts align in **core ideas** and **content**, even though they are from different PDF pages. The shared focus on text generation, summarization, and performance metrics accounts for the high similarity.  \n",
      "\n",
      "**Conclusion**: The high similarity is due to the **overlap in topics** (text generation, summarization, paraphrasing) and the **common structure of the information**, which aligns the two texts to a similar content.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 51.21%\n",
      "The similarity score of 51.21% between the query and matched PDF pages is justified by the following key points:\n",
      "\n",
      "1. **Shared Focus on LLM-Generated Text Detection**: Both documents discuss LLM models (LLaMa 2, GPT-4) and their performance metrics in text classification, such as 92% and 95% accuracy. The query emphasizes the comparison between different models and their effectiveness in detecting text, while the matched text highlights the detection process and its impact on model performance.\n",
      "\n",
      "2. **Overlap in Detection Methods**: The query text mentions 92% and 95% accuracy from different models (LLaMa 2 vs. GPT-4) and the matched text discusses similar results across models (e.g., 92% accuracy from T5 and Sumy). This direct correlation in performance metrics explains the similarity.\n",
      "\n",
      "3. **Incorporation of Human-Paraphrased Texts**: Both documents address how human-paraphrased texts influence detection models. The query text discusses the impact of paraphrasing on classifiers, while the matched text focuses on the effectiveness of such edits in improving detection. This overlap in the role of paraphrasing is central to the similarity.\n",
      "\n",
      "4. **Structural and Content Alignment**: The query includes figures from LLaMa 2 and GPT-4, and the matched text includes a flowchart of text generation and classification. Both documents align in their focus on LLM-based detection methods and their influence on performance, contributing to a high degree of similarity.\n",
      "\n",
      "In conclusion, the similarity between the two documents is due to their shared emphasis on LLM-generated text detection, methodologies, and the impact of paraphrasing on detection systems.\n",
      "\n",
      "=== Query Page 12 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 56.74%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query**: \"AI technology is advancing, while machine learning is transforming the field.\"  \n",
      "   - **Matched PDF**: \"AI technology is enhancing through machine learning, and machine learning is enabling new possibilities.\"  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   - These paragraphs share the idea that AI technology is advancing and machine learning is central to its development. Both discuss complementary roles: one emphasizes AI’s progress, the other highlights machine learning’s transformative impact.  \n",
      "\n",
      "3. **Why Similar**:  \n",
      "   - They both focus on AI’s role in advancing technologies and its influence on innovation, making them closely related in their discussion.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_17 | Score: 50.87%\n",
      "**Similarity Explanation:**\n",
      "\n",
      "1. **Key Topics and Ideas:**  \n",
      "   Both documents discuss summarization methods, with the query focusing on algorithms like BART, T5, Gensim, and Sumy, and the matched file highlighting similar models (e.g., XSum, BART, Gensim). The query and matched text share a focus on comparing accuracy metrics and summarization techniques, which are central to the similarity score.\n",
      "\n",
      "2. **Key Figures and Metrics:**  \n",
      "   The query includes metrics such as \"average over 10 CV folds\" and \"0.7540–1.0,\" while the matched file also references similar performance metrics (e.g., 0.7540–1.0). The figures in both documents show ROC curves, which visually represent similar results, reinforcing the similarity in their data.\n",
      "\n",
      "**Highlighted Sentences/Paragraphs:**  \n",
      "- **Query Page:** \"Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.\"  \n",
      "- **Matched Page:** \"0.7540–1.0; 0.9221–1.0; 0.9664–1.0; 0.9753–0.7954; 0.9611–0.9753; 0.9648–1.0; 0.9735–0.9381; 0.948–0.7954; 1.0.\"  \n",
      "- **Explanation:** Both documents highlight the performance metrics of summarization models, with the query emphasizing accuracy and the matched file showing similar results across models, validating the similarity in their comparison.\n",
      "\n",
      "**Justification:**  \n",
      "The similarity score of 50.87% reflects a thorough comparison of summarization methods, covering key metrics, figures, and the overall focus on performance across different algorithms. The overlapping themes and metrics in both documents directly support the similarity.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_19 | Score: 50.11%\n",
      "**Similarity Explanation:**  \n",
      "The query page text highlights the table with summarization method accuracies, while the matched page text includes figures showing ROC curves with human and QQP data. Both documents present the same results regarding summarization performance, indicating a similarity in their focus and outcomes.  \n",
      "\n",
      "**Highlighted Sentences or Paragraphs:**  \n",
      "1. **Query Page Text:**  \n",
      "   *\"Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.\"*  \n",
      "   *\"BART summarizer and Wikipedia – about 96 %, and BART summarizer and Sumy summarizer – about 97 %.\"*  \n",
      "\n",
      "2. **Matched Page Text:**  \n",
      "   *\"Fig. 29. ROC Curve with Full Human Data and Non-watermarked QQP LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from QQP OPT-generated Text).\"*  \n",
      "   *\"Fig. 30. ROC Curve with Full Human Data and Watermarked QQP LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from QQP OPT-generated Text).\"*  \n",
      "\n",
      "**Similarity Justification:**  \n",
      "The tables and figures from both documents align in their presentation of summarization results. Both documents emphasize the effectiveness of summarization methods across different models and datasets, confirming a strong similarity in content and main ideas.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_18 | Score: 49.90%\n",
      "**1. Highlight sentences or paragraphs from the query page that have similar information or main idea:**  \n",
      "- **Query Page Text**:  \n",
      "  *\"K. Przystalski et al. Table 10 Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.\"*  \n",
      "  *\"Wikipedia sum Sumy T5 BART Gensim Sumy 0.7540 1.0 T5 0.864 0.9221 1.0 BART 0.9664 0.9735 0.9381 1.0 Gensim 0.9611 0.9753 0.948 0.7954 1.0 GPT-3.5 0.7540 0.8398 0.8889 0.9648 0.9634 GPT-4 0.7283 0.8071 0.8967 0.9501 0.9469 LLaMa 2 0.8924 0.9129 0.9034 0.8135 0.8986 LLaMa 3 0.6865 0.79 0.8757 0.9622 0.9509 Orca 0.9046 0.9223 0.9107 0.7561 0.8717 Falcon 0.8362 0.8875 0.8353 0.7935 0.8769 96% BART summarizer and Wikipedia – about 96%...\"*  \n",
      "\n",
      "- **Matched File**:  \n",
      "  *\"Fig. 26. ROC Curve with Full Human Data and Watermarked XSum LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from XSum OPT-generated Text).*  \n",
      "  *\"Fig. 27. ROC Curve with Full Human Data and Non-watermarked QQP LLM-Data (Paraphrases generated with DIPPER (left) and BART (right) from QQP GPT-generated Text).*  \n",
      "\n",
      "**2. Show corresponding sentences or paragraphs from the matched PDF**:  \n",
      "- **Query Page**:  \n",
      "  *\"The summarisation methods achieve similar results in the decision tree experiment. We can conclude that we will achieve similar results in LGBM for the summarisation methods.\"*  \n",
      "  *\"The summarisers do have a distinctive way of text summarisation that can be found using stylometry.\"*  \n",
      "\n",
      "**3. Explain why these parts are considered similar**:  \n",
      "- Both documents discuss **summarisation methods** and their **performance in text generation tasks**, with a focus on **accuracy, comparison between models**, and **stylometric analysis**. The similarity in results (e.g., accuracy percentages, comparison graphs) and the **explaining factors** (like BART/T5's high recognisability, or the role of grammatical features) highlight the **shared focus on method comparison** and **stylometric validation**. The matched file's figures further support this similarity by showing **similar results across different models**.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 49.58%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**:  \n",
      "     Table 10: Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.  \n",
      "     *Similar to:*  \n",
      "     - Table 10: Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.  \n",
      "\n",
      "   - **Matched Page**:  \n",
      "     Table 10: Accuracies of summarization methods text generation recognition using decision trees. Average over 10 CV folds.  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   Both PDFs highlight the same table, showing that summarization methods yield consistent results across different models (e.g., decision trees, BART, Gensim, etc.). The similarity in the table underscores their comparable performance in text summarization tasks.  \n",
      "\n",
      "3. **Similarity Justification**:  \n",
      "   The query and matched files share the same table, confirming that summarization methods across different models (e.g., decision trees, BART, Gensim, etc.) yield similar accuracy results. This overlap indicates that the summarization techniques are effectively comparable in their performance across various contexts.\n",
      "\n",
      "=== Query Page 13 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_4 | Score: 56.80%\n",
      "1. **Highlight sentences from the query and matched files:**  \n",
      "   - **Query Page Text:**  \n",
      "     *\"Table 11 Commercial applications predictions. Model Falcon GPT-3 GPT-4 LLaMA 2 LLaMA 3 Orca Human\"*  \n",
      "     *\"GPTZero prompt #1 98 % 100 % 96 % 98 % 98 % 100 % GPTZero prompt #2 100 % 99 % 93 % 95 % 100 % N/A\"*  \n",
      "     *\"HIX prompt #1 3 % 5 % 3 % 5 % 4 % 0 % 100 %\"*  \n",
      "\n",
      "   - **Matched File:**  \n",
      "     *\"Natural Language Processing Journal 11 (2025) 100151\"*  \n",
      "     *\"ROC Curve Comparison: (a) Human-generated Documents/Paraphrases vs DIPPER-generated Paraphrases from Non-watermarked MRPC GPT2-generated Text, (b) Human-generated Documents/Paraphrases vs BART-generated Paraphrases from Non-watermarked MRPC GPT2-generated Text, (c) Human-generated Documents/Paraphrases vs DIPPER-generated Paraphrases from Watermarked MRPC GPT2-generated Text, (d) Human-generated Documents/Paraphrases vs BART-generated Paraphrases from Watermarked MRPC GPT2-generated Text.\"*  \n",
      "\n",
      "   - **Similarity Explanation:**  \n",
      "     Both texts focus on models (Falcon, GPT-3, etc.) and performance metrics (accuracy, TPR, FPR). The ROC curve comparisons in the matched file align with the query's emphasis on detecting LLM-generated paraphrases and evaluating detection accuracy. The structure of the predictions and analysis mirrors the matching file's focus on classification performance and research gaps.  \n",
      "\n",
      "2. **Show corresponding sentences and explain similarity:**  \n",
      "   - **Query:** *\"Commercial applications predictions. Model Falcon GPT-3 GPT-4 LLaMA 2 LLaMA 3 Orca Human\"*  \n",
      "     *\"GPTZero prompt #1 98 % 100 % 96 % 98 % 98 % 100 % GPTZero prompt #2 100 % 99 % 93 % 95 % 100 % N/A\"*  \n",
      "   - **Matched:** *\"Natural Language Processing Journal 11 (2025) 100151\"*  \n",
      "     *\"ROC Curve Comparison: (a) Human-generated Documents/Paraphrases vs DIPPER-generated Paraphrases from Non-watermarked MRPC GPT2-generated Text, (b) Human-generated Documents/Paraphrases vs BART-generated Paraphrases from Non-watermarked MRPC GPT2-generated Text, (c) Human-generated Documents/Paraphrases vs DIPPER-generated Paraphrases from Watermarked MRPC GPT2-generated Text, (d) Human-generated Documents/Paraphrases vs BART-generated Paraphrases from Watermarked MRPC GPT2-generated Text.\"*  \n",
      "\n",
      "   - **Similarity:** Both texts discuss models, performance metrics, and classification methods (e.g., TPR, FPR, ROC curves). The matched file's structure (e.g., table, ROC comparison) aligns with the query's emphasis on detection accuracy and statistical analysis.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_1 | Score: 55.56%\n",
      "The similarity score of 55.56% between the query and matched pages is explained by the following points:\n",
      "\n",
      "1. **Key Concepts**: Both texts discuss LLM-generated text detection and its effectiveness in distinguishing between human and model-generated text. The query highlights stylometric approaches and model predictions, while the matched file details classification methods and performance metrics (e.g., accuracy in detecting paraphrased texts).\n",
      "\n",
      "2. **Data Sets and Experiments**: Both pages reference datasets and experiments, such as the \"Human & LLM Paraphrase Collection (HLPC)\" dataset, which are central to the study. The query's focus on commercial applications and model performance aligns with the matched file's emphasis on detection accuracy and classification effectiveness.\n",
      "\n",
      "3. **Classification and Detection Methods**: The query and matched file both use SOTA AI paraphrasers and detectors for classification. The similarity in classification methods (e.g., zero-shot detection and watermarking) and the inclusion of human-paraphrased texts in both contexts contribute to the high similarity score.\n",
      "\n",
      "4. **Structural Similarity**: The query page text (e.g., Table 11) and the matched file (e.g., Fig. 2) share a structure with overlapping content, such as mean similarity scores across datasets and the flowchart of the LLM generation process.\n",
      "\n",
      "Overall, the similarity arises from overlapping themes, shared methodologies, and structural alignment in both texts, explaining the 55.56% similarity.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_9 | Score: 54.25%\n",
      "1. **Query Page**:  \n",
      "   - \"You should be careful with the information you share.\"  \n",
      "   - **Matched Page**: \"In our review of the literature in Section 2 we found that existing LLMs are trained on corpora that do not contain H-PP information.\"  \n",
      "   - **Similarity**: Both sentences discuss the importance of H-PP in LLM training, highlighting its role in improving performance metrics like AUROC and accuracy.  \n",
      "\n",
      "2. **Query Page**:  \n",
      "   - \"To enable this study, we devise a data collection strategy and generate the HLPC dataset by leveraging and extending four existing data sources: MRPC, XSum, QQP and MultiPIT.\"  \n",
      "   - **Matched Page**: \"In our experiments, we observed that in all 3 sets of comparisons, including H-PP in classification is effective in promoting TPR@1%FPR...\"  \n",
      "   - **Similarity**: Both sentences emphasize the effectiveness of H-PP in classification, focusing on its impact on key performance metrics.  \n",
      "\n",
      "3. **Query Page**:  \n",
      "   - \"The sentences in the chosen datasets are relatively short, with a mean token length of 79.78 for H-DOC and 17.61 for H-PP.\"  \n",
      "   - **Matched Page**: \"In the 1st set of comparison, the results show that TPR@1%FPR increases in all scenarios, but AUROC and accuracy decrease if non-watermarked LLM-DOC are used...\"  \n",
      "   - **Similarity**: Both sentences highlight the effect of H-PP on classification metrics, emphasizing its impact on TPR@1%FPR and AUROC.  \n",
      "\n",
      "**Explanations**:  \n",
      "- These parts are similar because they both focus on the role of H-PP in LLM detection and classification performance, with key points about its effectiveness and impact on specific metrics.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_8 | Score: 53.31%\n",
      "**Task 1:**  \n",
      "**Query Page:**  \n",
      "*\"Text generation techniques, such as paraphrasing, are key to improving text quality.\"*  \n",
      "\n",
      "**Matched PDF:**  \n",
      "*\"Similar techniques, like paraphrasing, enhance text quality by improving clarity and reducing errors.\"*  \n",
      "\n",
      "**Similarity Explanation:**  \n",
      "Both sentences highlight the role of paraphrasing in text generation, emphasizing its impact on quality. The query focuses on techniques, while the PDF discusses similar methods, reinforcing the similarity in main idea.  \n",
      "\n",
      "**Task 2:**  \n",
      "**Matched PDF:**  \n",
      "*\"Text generation methods, including paraphrasing, improve text quality by increasing clarity and reducing errors.\"*  \n",
      "\n",
      "**Task 3:**  \n",
      "**Similarity Explanation:**  \n",
      "Both sentences emphasize paraphrasing as a technique driving text quality, aligning with the query's focus on text generation. The matched PDF directly supports this theme, reinforcing the similarity in core idea.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 51.98%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: \"Table 11: Commercial applications predictions. Model: Falcon GPT-3 GPT-4 LLaMA 2 LLaMA 3 Orca Human. GPTZero prompt #1 98% 100% 96% 98% 98% 100% GPTZero prompt #2 100% 99% 93% 95% 100% N/A HIX prompt #1 3% 5% 3% 5% 4% 0% 100%\".  \n",
      "   - **Matched Page**: \"References: Allam, A.M.N., Haggag, M.H., 2012. The question answering systems: A survey. Int. J. Res. Rev. Inf. Sci. (IJRRIS) 2 (3). An, H., Acquaye, C., Wang, C., Li, Z., Rudinger, R., 2024. Do large language models discriminate in hiring decisions...\".  \n",
      "\n",
      "2. **Corresponding Sentences**:  \n",
      "   - **Query Page**: \"Stylometric approach achieves better results. In Xu et al. (2024) FreqMark method was proposed... accuracy of 98% shows that not only stylometry-based methods... N/A\".  \n",
      "   - **Matched Page**: \"References: Barreto, F., Moharkar, L., Shirodkar, M., Sarode, V., Gonsalves, S., Johns, A., 2023. Generative artificial intelligence: Opportunities...\".  \n",
      "\n",
      "3. **Similarity Explanation**:  \n",
      "   Both documents focus on **model performance metrics** (accuracy, precision, recall) and **stylometric analysis** for distinguishing between human and AI-generated text. The query emphasizes commercial applications, model predictions, and stylometric effectiveness, while the matched file provides references to similar methods and discusses their application in hiring and detection. This alignment highlights a **main idea** centered on model performance and stylometry’s role in text classification.\n",
      "\n",
      "=== Query Page 14 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 44.42%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: \"Our findings suggest that general-purpose LLMs, particularly GPT-3.5, offer viable tools for estimating VaR and ES in contexts where agility and numerical precision are critical.\"  \n",
      "   - **Matched PDF**: \"The GARCH(1,1) model (Bollerslev, 1986) is renowned for its capacity to capture volatility clustering, a prevalent pattern in financial returns...\"  \n",
      "   - **Explanation**: Both pages discuss generative AI's applications in financial risk analytics, focusing on models like GARCH and their specifications.  \n",
      "\n",
      "2. **Matched PDF Sentences**:  \n",
      "   - \"The GARCH model is specified as follows: 𝑟𝑡 = 𝑍𝑡𝜎𝑡, 𝑍𝑡 ∼ 𝑢(0,1), 𝜎2𝑡 = 𝜔 + 𝛽1𝑟2𝑡−1 + 𝛼1𝜎2𝑡−1, (A.1)\"  \n",
      "   - \"To further strengthen the GARCH model and improve its adaptability to sudden structural shifts, we incorporate the Local Parametric Approach (LPA), which uses Local Change Point detection...\"  \n",
      "\n",
      "3. **Similarity Explanation**: Both texts focus on the same subject (generative AI in financial risk), the models discussed (GARCH and LPA), and their applications in financial contexts. The similarity lies in the technical specifications and the broader implications of these models.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_10 | Score: 43.63%\n",
      "To process the tasks effectively, follow these steps:\n",
      "\n",
      "### **1. Task 1: Highlight Similar Sentences**\n",
      "- **Process**: Analyze the query page to identify sentences or paragraphs with similar information or main ideas. Use the dataset to find patterns in the text.\n",
      "- **Output**: Present the highlighted sentences and explain their similarity in clear, natural language.\n",
      "\n",
      "### **2. Task 2: Show Matched PDF and Explain Similarity**\n",
      "- **Process**: Retrieve the matched PDF content and compare it with the query page. Explain why the sentences are similar (e.g., content overlap, thematic consistency).\n",
      "- **Output**: Provide the matched PDF content and a brief explanation of similarity.\n",
      "\n",
      "### **3. Statistical Analysis**\n",
      "- **Process**: Review the regression results (logistic regression with variables condition and subject type) to understand how the model structured information. Analyze the semantic structure experiment to assess the model's ability to organize content.\n",
      "- **Output**: Present the regression findings and the semantic structure results, highlighting how they support the tasks.\n",
      "\n",
      "### **Integration**\n",
      "- Ensure the tasks are executed and results are aligned with the dataset's data and statistical findings. This helps validate the processes and explain the contributions to understanding the tasks.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_17 | Score: 43.29%\n",
      "1. **Highlight sentences from the query**:  \n",
      "   - **Query**: \"Language models are capable of handling recursively nested grammatical structures.\"  \n",
      "   - **PDF**: \"Analogy as the core of cognition.\"  \n",
      "   - **Explanation**: Both discuss how language models use analogy to model complex structures, aligning with the role of analogy in cognitive processes.  \n",
      "\n",
      "2. **Highlight sentences from the query**:  \n",
      "   - **Query**: \"Large language models are trained to solve problems.\"  \n",
      "   - **PDF**: \"The emergence of non-Bayesian in-context learning.\"  \n",
      "   - **Explanation**: Both focus on the generality and non-Bayesian nature of language model reasoning, similar to how analogy enables general cognitive processes.  \n",
      "\n",
      "3. **Explain similarity**:  \n",
      "   - The query’s emphasis on language models’ ability to handle recursive structures and general reasoning mirrors the PDF’s discussion of analogy’s role in cognitive modeling. Similarly, the focus on training for problem-solving and non-Bayesian reasoning in models corresponds to the PDF’s analysis of analogy as a foundational aspect of human cognition.\n",
      "\n",
      "Matched PDF: 1-s2.0-S1071581925001466-main.pdf_page_13 | Score: 42.74%\n",
      "1. **Highlighted Sentences/Paragraphs**:  \n",
      "   The query mentions that mobile phone reminders can help with self-care. The corresponding sentences from the matched PDF are:  \n",
      "   - *\"Mobile phone reminders can enhance self-care by providing structured support.\"* (PDF: \"Large language models in qualitative research: Uses, tensions, and intentions.\")  \n",
      "   - *\"The implementation of reminders can improve the self-care subdomains of informal caregivers.\"* (PDF: \"Uses, tensions, and intentions.\")  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   These sentences share similar ideas about the role of reminders in supporting self-care. Both focus on how technology (mobile phone reminders) aids informal caregivers, emphasizing efficiency and effectiveness. The similarity lies in their emphasis on technology’s role in improving self-care outcomes.  \n",
      "\n",
      "**Why These Parts Are Similar**:  \n",
      "- Both sentences highlight the **benefit of technology (reminders)** in **supporting self-care**.  \n",
      "- They reference **structured support** and **efficiency** as key aspects of self-care.  \n",
      "- The context is **related to technology and its impact on personal care**, making them similar in theme and function.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_3 | Score: 42.31%\n",
      "1. **Highlight sentences from the query and matched PDF**  \n",
      "   - Query: \"LLM-VaR and LLM-ES for a given model 𝑀 as follows: VaR𝛼;𝑀  \n",
      "     𝑡 = −̂𝜎𝑡 𝑞𝛼, ES𝛼;𝑀  \n",
      "     𝑡 = { ̂𝜎𝑡  \n",
      "     𝛘(Φ−1(1 −𝛼)),  \n",
      "     𝑍𝑡 ∼ ̂𝜎𝑡  \n",
      "     𝛘,  \n",
      "     𝑍𝑡 ∼ 𝑡𝜈,  \n",
      "     (6)  \n",
      "     **Matching PDF**: The same structure is used for VaR and ES estimates.  \n",
      "   - **Why similar**: Both present the methodology for risk estimation, including VaR and ES calculation formulas.  \n",
      "\n",
      "2. **Highlight sentences from the query and matched PDF**  \n",
      "   - Query: \"We utilize GPT-3.5 Turbo, GPT-4, and GPT-4o to estimate VaR and ES.\"  \n",
      "   - **Matching PDF**: \"Rolling window approach with window length 𝑤 using historical log-returns as inputs.\"  \n",
      "   - **Why similar**: Both discuss the method of estimating risk measures using historical data and models.  \n",
      "\n",
      "3. **Highlight sentences from the query and matched PDF**  \n",
      "   - Query: \"The GARCH(1,1) model captures volatility clustering, while the EWMA model dynamically adjusts volatility.\"  \n",
      "   - **Matching PDF**: \"GARCH(1,1) effectively captures volatility clustering, while the EWMA model dynamically adjusts volatility based on market conditions.\"  \n",
      "   - **Why similar**: Both focus on traditional financial risk models and their enhancements for dynamic market behavior.\n",
      "\n",
      "=== Query Page 15 ===\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_15 | Score: 56.80%\n",
      "**Task 1: Highlight Sentences**  \n",
      "**Query Page**:  \n",
      "- \"S. Musker et al. Fig. A.14. Improvement in human and LLM proportion match to reference by question number across different conditions. Error bars show standard errors.\"  \n",
      "- \"A.5. Further details of LLM performance\"  \n",
      "\n",
      "**Matched Page Text**:  \n",
      "- \"Fig. A.15. Performance of all tested models in the Semantic Structure experiment.\"  \n",
      "- \"Some models perform quite poorly, for example Falcon-40B.\"  \n",
      "\n",
      "**Task 2: Show Corresponding Sentences**  \n",
      "**Query Page**:  \n",
      "- \"S. Musker et al. Fig. A.14. Improvement in human and LLM proportion match...\"  \n",
      "- \"A.5. Further details of LLM performance\"  \n",
      "\n",
      "**Matched Page Text**:  \n",
      "- \"Fig. A.15. Performance of all tested models...\"  \n",
      "- \"Some models perform quite poorly...\"  \n",
      "\n",
      "**Task 3: Explain Why They Are Similar**  \n",
      "Both texts focus on improving human-LMM match performance across experiments and evaluating model performance. The key similarity lies in discussing similar themes: enhancing human-LMM collaboration, evaluating model effectiveness, and analyzing performance across different conditions. This thematic overlap explains the 56.80% similarity score.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0749596X25000695-main.pdf_page_1 | Score: 50.90%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query Page**: Sentences discussing analogical reasoning tasks (e.g., \"GPT-3 could match or exceed typical human performance on analogical tasks...\") and the role of semantic structure in guiding inference.  \n",
      "   - **Matched PDF**: Corresponding text mentions similar topics, such as \"semantic structure and semantic content\" in tasks.  \n",
      "\n",
      "2. **Explanation**:  \n",
      "   These parts are similar because both the query and the PDF focus on the **focus on structure (semantic relationships)** and **semantic content** in analogical reasoning tasks. The query highlights how LLMs perform on symbolic analogies, while the PDF reinforces the importance of both structural and content-based reasoning in mapping abstract concepts.  \n",
      "\n",
      "3. **PDF Reference**:  \n",
      "   The matched PDF contains the tasks and results discussed in the query, reinforcing the idea that LLMs can achieve human-level performance on complex tasks requiring abstract rule induction and re-representation.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_20 | Score: 47.46%\n",
      "**Task 1: Highlight Similar Sentences/Paragraphs**  \n",
      "- **Query:** \"Large language models (LLMs) enable tasks like question answering, text generation, and reasoning.\"  \n",
      "- **Matched:** \"NLP systems, including large language models, are designed to process and generate human-like text.\"  \n",
      "- **Similarity:** Both sentences highlight LLMs’ capabilities, though the query emphasizes their use cases, while the matched text focuses on their applications in NLP.\n",
      "\n",
      "**Task 2: Show Corresponding Sentences/Paragraphs**  \n",
      "- **Query:**  \n",
      "  *\"Large language models (LLMs) enable tasks like question answering, text generation, and reasoning.\"*  \n",
      "- **Matched:**  \n",
      "  *\"NLP systems, including large language models, are designed to process and generate human-like text.\"*  \n",
      "\n",
      "**Task 3: Explain Why They Are Similar**  \n",
      "- Both texts discuss **large language models (LLMs)**, emphasizing their **ability to process and generate human-like text**. While the query focuses on their **capabilities** and the matched text highlights their **applications** in NLP, the core idea remains the same: LLMs are tools that simulate human reasoning. This similarity lies in the shared theme of their function, though the focus differs slightly.\n",
      "\n",
      "Matched PDF: 1-s2.0-S2949719125000275-main.pdf_page_5 | Score: 45.71%\n",
      "1. **Highlight Sentences/Paragraphs**:  \n",
      "   Look for sentences or paragraphs in the query that share similar ideas or main themes. For example, if the query discusses AI, identify related sentences in the matched PDF.  \n",
      "\n",
      "2. **Show Corresponding Sentences/Paragraphs**:  \n",
      "   Locate the matched sentences from the PDF and explain their similarity. For instance, if the query mentions a human-generated text, the matched PDF should include a similar human-generated sentence.  \n",
      "\n",
      "3. **Explain Similarity**:  \n",
      "   Briefly explain why the highlighted sentences are similar. For example, if the query focuses on paraphrasing, the matched PDF's sentences should align in terms of semantic or context.  \n",
      "\n",
      "**Example**:  \n",
      "- Query: \"AI is a powerful tool, but it requires human oversight.\"  \n",
      "- Matched PDF: \"Human oversight ensures AI aligns with human values.\"  \n",
      "- Explanation: Both sentences emphasize human involvement, making them similar in meaning.\n",
      "\n",
      "Matched PDF: 1-s2.0-S0957417425022948-main.pdf_page_12 | Score: 45.33%\n",
      "1. **Highlighted Sentences**:  \n",
      "   - **Query**: \"In conclusion, our findings suggest that general-purpose LLMs, particularly GPT-3.5, offer viable tools for estimating VaR and ES in contexts where agility and numerical precision are critical.\"  \n",
      "   - **PDF**: \"To further strengthen the GARCH model and improve its adaptability to sudden structural shifts, we incorporate the Local Parametric Approach (LPA)...\"  \n",
      "\n",
      "   **Explanation**: Both sentences highlight the use of LLMs in financial risk estimation, emphasizing their role in handling volatility and structural shifts, which aligns with the PDF's focus on GARCH models.\n",
      "\n",
      "2. **Matched PDF Sentences**:  \n",
      "   - **Query**: \"The GARCH(1,1) model (Bollerslev, 1986) is renowned for its capacity to capture volatility clustering...\"  \n",
      "   - **PDF**: \"The Local Parametric Approach (LPA)... allows the model to detect and adapt to structural breaks...\"  \n",
      "\n",
      "   **Explanation**: These sentences demonstrate the similarity in discussing LLM applications for financial risk analytics, tying the query's focus on LLM tools to the PDF's explanation of model adaptability.  \n",
      "\n",
      "3. **Why These Parts Are Similar**:  \n",
      "   Both the query and the PDF discuss LLMs in the context of financial risk analysis, emphasizing their role in handling volatility and structural shifts. This shared theme underscores the relevance of LLMs in financial analytics, even though the specific models differ.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict\n",
    "import ollama\n",
    "import re\n",
    "\n",
    "# ---- PDF Helper to extract text ----\n",
    "def extract_page_text(pdf_path, page_number):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    if 0 <= page_number < len(doc):\n",
    "        text = doc[page_number].get_text(\"text\")\n",
    "    else:\n",
    "        text = \"\"\n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "\n",
    "# ---- Milvus Search Function ----\n",
    "def query_with_pdf(pdf_path, top_k=5):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    results_all = []\n",
    "    similarity_scores = defaultdict(list)\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        if not page_text:\n",
    "            continue\n",
    "\n",
    "        # Encode page text\n",
    "        query_vec = model.encode([page_text])[0].tolist()\n",
    "        search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
    "        results = collection.search(\n",
    "            [query_vec],\n",
    "            \"embedding\",\n",
    "            param=search_params,\n",
    "            limit=top_k,\n",
    "            output_fields=[\"doc_name\"]\n",
    "        )\n",
    "        results_all.append((page_num, results))\n",
    "\n",
    "        # Collect similarity scores\n",
    "        for hit in results[0]:\n",
    "            full_name = hit.entity.get(\"doc_name\")\n",
    "            pdf_base = full_name.split(\"_page_\")[0]\n",
    "            similarity_percentage = hit.score * 100\n",
    "            similarity_scores[pdf_base].append(similarity_percentage)\n",
    "\n",
    "    doc.close()\n",
    "    return results_all\n",
    "\n",
    "# ---- LLM Comparison Function ----\n",
    "def compare_with_llm(query_pdf_path, results_all):\n",
    "    for page_num, hits in results_all:\n",
    "        query_text = extract_page_text(query_pdf_path, page_num)\n",
    "        if not query_text:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== Query Page {page_num} ===\")\n",
    "\n",
    "        for hit in hits[0]:\n",
    "            match_name = hit.entity.get(\"doc_name\")\n",
    "            similarity_percentage = hit.score * 100\n",
    "\n",
    "            # Parse file + page number\n",
    "            match_pdf_file, match_page_str = match_name.split(\"_page_\")\n",
    "            match_page = int(match_page_str)\n",
    "\n",
    "            # Full dataset path\n",
    "            matched_pdf_path = f\"/home/natcha/rag_document/dataset/{match_pdf_file}\"\n",
    "\n",
    "            # Extract matched page text\n",
    "            matched_text = extract_page_text(matched_pdf_path, match_page)\n",
    "\n",
    "            # Skip if empty\n",
    "            if not matched_text:\n",
    "                continue\n",
    "\n",
    "            # Run LLM explanation\n",
    "            response = ollama.generate(\n",
    "                model=\"qwen3:0.6b-q4_K_M\",\n",
    "                prompt=f\"\"\"\n",
    "You are analyzing two pieces of text from different PDF pages.\n",
    "Compare the following two PDF page texts and justify why their similarity score is {similarity_percentage:.2f}%:\n",
    "\n",
    "Query file: {query_pdf_path}, Page {page_num}  \n",
    "Matched file: {match_pdf_file}.pdf, Page {match_page}  \n",
    "\n",
    "---\n",
    "Query Page Text:\n",
    "{query_text}\n",
    "\n",
    "---\n",
    "Matched Page Text:\n",
    "{matched_text}\n",
    "\n",
    "Tasks:\n",
    "1. Highlight sentences or paragraphs from the query page that have similar information or main idea.  \n",
    "2. Show the corresponding sentences or paragraphs from the matched PDF.  \n",
    "3. Explain briefly why these parts are considered similar in clear, natural language.\n",
    "\"\"\"\n",
    "            )\n",
    "\n",
    "            print(f\"\\nMatched PDF: {match_name} | Score: {similarity_percentage:.2f}%\")\n",
    "            response_text = response[\"response\"]  \n",
    "            match = re.search(r\"</think>\\s*(.*)\", response_text, re.DOTALL)\n",
    "            if match:\n",
    "                extracted_text = match.group(1).strip()\n",
    "            else:\n",
    "                extracted_text = \"\"\n",
    "            print(extracted_text)\n",
    "\n",
    "# ---- Run Everything ----\n",
    "query_pdf_filepath = \"/home/natcha/rag_document/1-s2.0-S0957417425026181-main.pdf\"\n",
    "\n",
    "# Step 1: Search\n",
    "results_all = query_with_pdf(query_pdf_filepath, top_k=5)\n",
    "\n",
    "# Step 2: Compare with LLM\n",
    "compare_with_llm(query_pdf_filepath, results_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text:\n",
      "\n",
      "**1. Highlighted Sentences/Paragraphs:**  \n",
      "- **Query Page:**  \n",
      "  - \"LLM-generated text issues like bias, information accuracy, and potential problems with automatic text generation\" (first paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (second paragraph).  \n",
      "  - \"Detection methods like zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "- **Matched PDF:**  \n",
      "  - \"LLM-generated text issues such as bias and information accuracy\" (second paragraph).  \n",
      "  - \"Paraphrasing attacks in LLM-generated text detection\" (third paragraph).  \n",
      "  - \"Detection methods including zero-shot and watermarking\" (third paragraph).  \n",
      "\n",
      "**2. Explanation:**  \n",
      "- The query’s first paragraph highlights the same core problems as the matched PDF’s second paragraph, focusing on biases, accuracy, and detection vulnerabilities.  \n",
      "- The matched PDF’s second paragraph directly repeats the issue with paraphrasing attacks, which aligns with the query’s third paragraph on detection vulnerabilities.  \n",
      "- The third paragraph of the query and the third paragraph of the matched PDF both emphasize detection methods (zero-shot and watermarking), making these parts similar in content and structure.  \n",
      "\n",
      "These sections share a logical flow, with the query building on similar themes to the matched PDF, reinforcing consistency in information.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragdoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
